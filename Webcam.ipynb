{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2SoUsM-ryO3A"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import math\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l_vAfRwvyhJF"
      },
      "outputs": [],
      "source": [
        "FIRE_WEIGHTS = \"Models/Fire Detection/fire.pt\"\n",
        "WEAPONS_WEIGHTS = \"Models/weapon Detection/best.pt\"\n",
        "VIOLENCE_WEIGHTS = \"Models/Violence Detection/ViolenceDet.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = {\n",
        "    \"generic\": [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
        "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
        "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
        "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
        "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
        "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
        "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
        "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
        "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
        "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
        "              ],\n",
        "    \"fire\" : [\"fire\",\"smoke\"],\n",
        "    \"violence\":[\"Violence\",\"Weapons\"],\n",
        "    \"weapons\" : [\"Grenade\",\"Handgun\",\"Rifle\",\"Steel arms\"]\n",
        "    # \"abduction\":[\"Kidnap\", \"Non Kidnap\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {}\n",
        "models[\"generic\"] = YOLO(\"yolov8n.pt\")\n",
        "models[\"fire\"] = YOLO(FIRE_WEIGHTS)\n",
        "models[\"weapons\"] = YOLO(WEAPONS_WEIGHTS)\n",
        "models[\"violence\"] = YOLO(VIOLENCE_WEIGHTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pygame 2.5.2 (SDL 2.28.3, Python 3.11.7)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pygame\n",
        "import matplotlib.pyplot as plt\n",
        "# Initialize pygame\n",
        "pygame.mixer.init()\n",
        "\n",
        "# Load siren sound\n",
        "siren_sound = pygame.mixer.Sound('police-6007.mp3')\n",
        "\n",
        "# Video capturing starts\n",
        "def tampering(frame):\n",
        "    # cap = cv2.VideoCapture(0)\n",
        "    fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "    # ret, frame = cap.read()\n",
        "    fgmask = fgbg.apply(frame)\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    \n",
        "    if frame is None:\n",
        "        print(\"End of frame\")\n",
        "    else:\n",
        "        a = 0\n",
        "        bounding_rect = []\n",
        "        fgmask = fgbg.apply(frame)\n",
        "        fgmask = cv2.erode(fgmask, kernel, iterations=5) \n",
        "        fgmask = cv2.dilate(fgmask, kernel, iterations=5)\n",
        "        cv2.imshow('frame', frame)\n",
        "        contours, _ = cv2.findContours(fgmask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for i in range(len(contours)):\n",
        "            bounding_rect.append(cv2.boundingRect(contours[i]))\n",
        "        for i in range(len(contours)):\n",
        "            if bounding_rect[i][2] >= 40 or bounding_rect[i][3] >= 40:\n",
        "                a = a + (bounding_rect[i][2]) * bounding_rect[i][3]\n",
        "            if a >= int(frame.shape[0]) * int(frame.shape[1]) / 3:\n",
        "                cv2.putText(frame, \"TAMPERING DETECTED\", (5, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
        "                # Play siren sound\n",
        "                siren_sound.play()\n",
        "            cv2.imshow('frame', frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "def create_csv():\n",
        "  try:\n",
        "    df = pd.read_csv('anomalies.csv')\n",
        "  except FileNotFoundError:\n",
        "    df = pd.DataFrame(columns=['Timestamp','Type of anomaly' ,'Number of People present', 'Path of image'])\n",
        "    df.to_csv('anomalies.csv', index=False)\n",
        "  return df\n",
        "\n",
        "def append_to_csv(df, timestamp, num_inmates, image_path, typeofanomaly=\"\"):\n",
        "  new_data = {'Timestamp': timestamp, 'Type of anomaly':typeofanomaly, 'Number of People present': num_inmates, 'Path of image': image_path}\n",
        "  new_data_df = pd.DataFrame.from_dict(new_data, orient='index').T\n",
        "  df = pd.concat([df, new_data_df], ignore_index=True)\n",
        "  df.to_csv('anomalies.csv', index=False)\n",
        "\n",
        "inmatesthresholdtime = 2\n",
        "anomaly_count = {} \n",
        "df = create_csv()\n",
        "\n",
        "def process_model(model, img, classNames, model_name, numinmates , savetodir=\"frames\"):\n",
        "    global inmatesthresholdtime, anomaly_count, df\n",
        "    \n",
        "    results = model(img, stream=True)\n",
        "    inmates = 0\n",
        "    anomalies = []\n",
        "    typeofanomaly = {\n",
        "            \"generic\": \"crowd\",\n",
        "            \"fire\": \"Fire\",\n",
        "            \"weapons\": \"Weapons\",\n",
        "            \"violence\": \"Violence\",\n",
        "  \n",
        "        }\n",
        "    for r in results:\n",
        "        boxes = r.boxes\n",
        "        for box in boxes:\n",
        "            cls = int(box.cls[0])\n",
        "            confidence = math.ceil((box.conf[0]*100))/100\n",
        "            if confidence < 0.6:\n",
        "                continue\n",
        "            if cls >= len(classNames):\n",
        "                print(\"Error: Class index out of range\")\n",
        "                continue\n",
        "            accepted_list = [\"person\", \"fire\", \"Grenade\", \"Handgun\", \"Rifle\", \"Steel arms\",\"Violence\",\"Kidnap\", \"Not Kidnap\"]\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
        "            if model_name == \"generic\" and classNames[cls] == \"person\":\n",
        "                inmates += 1\n",
        "            if classNames[cls] in accepted_list:\n",
        "                anomaly_key = (model_name, classNames[cls])\n",
        "                anomaly_count[anomaly_key] = anomaly_count.get(anomaly_key, 0) + 1\n",
        "                if anomaly_count[anomaly_key] >= 1:\n",
        "                    timestamp = time.strftime('%Y-%m-%d %H:%M:%S') \n",
        "                    anomaly_text = f\"{classNames[cls]} detected, storing the frame in the database as {savetodir}/{timestamp}.jpg at {timestamp}.\\n\"\n",
        "                    print(anomaly_text)\n",
        "                    anomalies.append(anomaly_text)\n",
        "                    anomaly_count[anomaly_key] = 0\n",
        "                    df = create_csv()\n",
        "                    # if model_name == \"generic\" and inmates > numinmates:\n",
        "                    #   append_to_csv(df, timestamp, inmates, f\"{savetodir}/{timestamp}.jpg\", typeofanomaly[model_name])\n",
        "                    # elif model_name != \"generic\":\n",
        "                    #   append_to_csv(df, timestamp, inmates, f\"{savetodir}/{timestamp}.jpg\", typeofanomaly[model_name])\n",
        "                    with open(\"anomalies.txt\", \"a\") as f:\n",
        "                        f.write(anomaly_text)\n",
        "                    # create the directory if it does not exist\n",
        "                    if not os.path.exists(savetodir):\n",
        "                        os.makedirs(savetodir)\n",
        "                    cv2.imwrite(filename=savetodir+\"/\"+timestamp+\".jpg\", img=img)\n",
        "                    \n",
        "                    \n",
        "            print(\"Confidence --->\", confidence)\n",
        "            print(\"Class name -->\", classNames[cls])\n",
        "            org = [x1, y1]\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            fontScale = 1\n",
        "            color = (255, 0, 0)\n",
        "            thickness = 2\n",
        "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
        "            \n",
        "    if inmatesthresholdtime <= 0:\n",
        "        inmatesthresholdtime = 2\n",
        "    else:\n",
        "        inmatesthresholdtime -= 1\n",
        "\n",
        "    with open(\"anomalies.txt\", \"a\") as f:\n",
        "        f.write(\" \".join(anomalies) )\n",
        "\n",
        "def start_webcam(models, classes):\n",
        "  cap = cv2.VideoCapture(1)\n",
        "  while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      print(\"Error: Unable to capture frame\")\n",
        "      break\n",
        "    for model_name, model in models.items():\n",
        "      process_model(model, frame.copy(), classes[model_name], model_name, 10)  # Pass a copy of frame to avoid modification across models\n",
        "    cv2.imshow(\"frame\", frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "      break\n",
        "\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run the function on demo video\n",
        "def start_demo(models, classes):\n",
        "    cap = cv2.VideoCapture(\"Models/weapon Detection/gun.mp4\")\n",
        "    # cap = cv2.VideoCapture(\"fire1.mp4\")\n",
        "\n",
        "    i = 0\n",
        "    while True:\n",
        "        i += 1\n",
        "        print(f\"{i}th frame\")\n",
        "        ret, frame = cap.read()\n",
        "        if i%10 != 0:\n",
        "            continue\n",
        "        if not ret:\n",
        "            print(\"Error: Unable to capture frame\")\n",
        "            break\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break \n",
        "        for model_name, model in models.items():\n",
        "            anomaly_detected = process_model(model, frame.copy(), classes[model_name], model_name, 10)  # Pass a copy of frame to avoid modification across models\n",
        "        if anomaly_detected:    \n",
        "            try:\n",
        "                tampering(frame)\n",
        "            except Exception as e:\n",
        "                print(\"An error occurred while tampering the image:\", e)\n",
        "            cv2.imshow(\"frame\", frame)\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "    \n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1th frame\n",
            "2th frame\n",
            "3th frame\n",
            "4th frame\n",
            "5th frame\n",
            "6th frame\n",
            "7th frame\n",
            "8th frame\n",
            "9th frame\n",
            "10th frame\n",
            "\n",
            "0: 384x640 (no detections), 78.9ms\n",
            "Speed: 5.5ms preprocess, 78.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 102.5ms\n",
            "Speed: 1.1ms preprocess, 102.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 109.6ms\n",
            "Speed: 0.7ms preprocess, 109.6ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 101.8ms\n",
            "Speed: 1.0ms preprocess, 101.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "11th frame\n",
            "12th frame\n",
            "13th frame\n",
            "14th frame\n",
            "15th frame\n",
            "16th frame\n",
            "17th frame\n",
            "18th frame\n",
            "19th frame\n",
            "20th frame\n",
            "\n",
            "0: 384x640 (no detections), 65.4ms\n",
            "Speed: 1.2ms preprocess, 65.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 97.7ms\n",
            "Speed: 0.9ms preprocess, 97.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 104.8ms\n",
            "Speed: 0.8ms preprocess, 104.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 105.8ms\n",
            "Speed: 1.0ms preprocess, 105.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "21th frame\n",
            "22th frame\n",
            "23th frame\n",
            "24th frame\n",
            "25th frame\n",
            "26th frame\n",
            "27th frame\n",
            "28th frame\n",
            "29th frame\n",
            "30th frame\n",
            "\n",
            "0: 384x640 (no detections), 52.2ms\n",
            "Speed: 0.9ms preprocess, 52.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 96.1ms\n",
            "Speed: 1.4ms preprocess, 96.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 103.2ms\n",
            "Speed: 1.0ms preprocess, 103.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 109.4ms\n",
            "Speed: 1.0ms preprocess, 109.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "31th frame\n",
            "32th frame\n",
            "33th frame\n",
            "34th frame\n",
            "35th frame\n",
            "36th frame\n",
            "37th frame\n",
            "38th frame\n",
            "39th frame\n",
            "40th frame\n",
            "\n",
            "0: 384x640 (no detections), 53.7ms\n",
            "Speed: 1.0ms preprocess, 53.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 97.1ms\n",
            "Speed: 1.2ms preprocess, 97.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.8ms\n",
            "Speed: 0.9ms preprocess, 89.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 95.3ms\n",
            "Speed: 0.7ms preprocess, 95.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "41th frame\n",
            "42th frame\n",
            "43th frame\n",
            "44th frame\n",
            "45th frame\n",
            "46th frame\n",
            "47th frame\n",
            "48th frame\n",
            "49th frame\n",
            "50th frame\n",
            "\n",
            "0: 384x640 (no detections), 52.1ms\n",
            "Speed: 1.3ms preprocess, 52.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 95.8ms\n",
            "Speed: 0.9ms preprocess, 95.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.7ms\n",
            "Speed: 0.8ms preprocess, 90.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 83.9ms\n",
            "Speed: 0.8ms preprocess, 83.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "51th frame\n",
            "52th frame\n",
            "53th frame\n",
            "54th frame\n",
            "55th frame\n",
            "56th frame\n",
            "57th frame\n",
            "58th frame\n",
            "59th frame\n",
            "60th frame\n",
            "\n",
            "0: 384x640 (no detections), 46.6ms\n",
            "Speed: 0.9ms preprocess, 46.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 85.8ms\n",
            "Speed: 0.9ms preprocess, 85.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 83.8ms\n",
            "Speed: 1.0ms preprocess, 83.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 82.9ms\n",
            "Speed: 0.9ms preprocess, 82.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "61th frame\n",
            "62th frame\n",
            "63th frame\n",
            "64th frame\n",
            "65th frame\n",
            "66th frame\n",
            "67th frame\n",
            "68th frame\n",
            "69th frame\n",
            "70th frame\n",
            "\n",
            "0: 384x640 (no detections), 46.0ms\n",
            "Speed: 0.9ms preprocess, 46.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 83.6ms\n",
            "Speed: 0.8ms preprocess, 83.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 84.3ms\n",
            "Speed: 0.9ms preprocess, 84.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.6ms\n",
            "Speed: 0.9ms preprocess, 86.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "71th frame\n",
            "72th frame\n",
            "73th frame\n",
            "74th frame\n",
            "75th frame\n",
            "76th frame\n",
            "77th frame\n",
            "78th frame\n",
            "79th frame\n",
            "80th frame\n",
            "\n",
            "0: 384x640 (no detections), 53.8ms\n",
            "Speed: 1.2ms preprocess, 53.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 85.7ms\n",
            "Speed: 0.7ms preprocess, 85.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 83.9ms\n",
            "Speed: 0.8ms preprocess, 83.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.3ms\n",
            "Speed: 1.1ms preprocess, 85.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "81th frame\n",
            "82th frame\n",
            "83th frame\n",
            "84th frame\n",
            "85th frame\n",
            "86th frame\n",
            "87th frame\n",
            "88th frame\n",
            "89th frame\n",
            "90th frame\n",
            "\n",
            "0: 384x640 (no detections), 46.1ms\n",
            "Speed: 0.9ms preprocess, 46.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 84.2ms\n",
            "Speed: 1.2ms preprocess, 84.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.3ms\n",
            "Speed: 1.0ms preprocess, 85.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.1ms\n",
            "Speed: 0.7ms preprocess, 85.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "91th frame\n",
            "92th frame\n",
            "93th frame\n",
            "94th frame\n",
            "95th frame\n",
            "96th frame\n",
            "97th frame\n",
            "98th frame\n",
            "99th frame\n",
            "100th frame\n",
            "\n",
            "0: 384x640 (no detections), 43.0ms\n",
            "Speed: 1.1ms preprocess, 43.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 85.9ms\n",
            "Speed: 0.8ms preprocess, 85.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.0ms\n",
            "Speed: 0.9ms preprocess, 86.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.8ms\n",
            "Speed: 1.0ms preprocess, 87.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "101th frame\n",
            "102th frame\n",
            "103th frame\n",
            "104th frame\n",
            "105th frame\n",
            "106th frame\n",
            "107th frame\n",
            "108th frame\n",
            "109th frame\n",
            "110th frame\n",
            "\n",
            "0: 384x640 (no detections), 45.3ms\n",
            "Speed: 0.9ms preprocess, 45.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.0ms\n",
            "Speed: 0.7ms preprocess, 88.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 94.6ms\n",
            "Speed: 0.6ms preprocess, 94.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.8ms\n",
            "Speed: 0.6ms preprocess, 86.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "111th frame\n",
            "112th frame\n",
            "113th frame\n",
            "114th frame\n",
            "115th frame\n",
            "116th frame\n",
            "117th frame\n",
            "118th frame\n",
            "119th frame\n",
            "120th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.2ms\n",
            "Speed: 1.0ms preprocess, 47.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 111.9ms\n",
            "Speed: 0.8ms preprocess, 111.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 102.1ms\n",
            "Speed: 0.8ms preprocess, 102.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.8ms\n",
            "Speed: 0.6ms preprocess, 88.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "121th frame\n",
            "122th frame\n",
            "123th frame\n",
            "124th frame\n",
            "125th frame\n",
            "126th frame\n",
            "127th frame\n",
            "128th frame\n",
            "129th frame\n",
            "130th frame\n",
            "\n",
            "0: 384x640 (no detections), 49.1ms\n",
            "Speed: 0.9ms preprocess, 49.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.2ms\n",
            "Speed: 0.7ms preprocess, 87.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.6ms\n",
            "Speed: 0.7ms preprocess, 89.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 91.6ms\n",
            "Speed: 0.8ms preprocess, 91.6ms inference, 8.0ms postprocess per image at shape (1, 3, 256, 448)\n",
            "131th frame\n",
            "132th frame\n",
            "133th frame\n",
            "134th frame\n",
            "135th frame\n",
            "136th frame\n",
            "137th frame\n",
            "138th frame\n",
            "139th frame\n",
            "140th frame\n",
            "\n",
            "0: 384x640 1 remote, 1 refrigerator, 53.7ms\n",
            "Speed: 1.1ms preprocess, 53.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.1ms\n",
            "Speed: 0.7ms preprocess, 87.1ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.7ms\n",
            "Speed: 0.7ms preprocess, 86.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 104.7ms\n",
            "Speed: 1.2ms preprocess, 104.7ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "141th frame\n",
            "142th frame\n",
            "143th frame\n",
            "144th frame\n",
            "145th frame\n",
            "146th frame\n",
            "147th frame\n",
            "148th frame\n",
            "149th frame\n",
            "150th frame\n",
            "\n",
            "0: 384x640 1 remote, 1 refrigerator, 44.8ms\n",
            "Speed: 0.9ms preprocess, 44.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.7ms\n",
            "Speed: 0.9ms preprocess, 88.7ms inference, 0.1ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.5ms\n",
            "Speed: 0.8ms preprocess, 86.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 102.4ms\n",
            "Speed: 0.7ms preprocess, 102.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "151th frame\n",
            "152th frame\n",
            "153th frame\n",
            "154th frame\n",
            "155th frame\n",
            "156th frame\n",
            "157th frame\n",
            "158th frame\n",
            "159th frame\n",
            "160th frame\n",
            "\n",
            "0: 384x640 1 person, 1 refrigerator, 46.8ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:54.jpg at 2024-03-17 00:05:54.\n",
            "\n",
            "Confidence ---> 0.75\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 46.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.0ms\n",
            "Speed: 0.9ms preprocess, 88.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.6ms\n",
            "Speed: 0.9ms preprocess, 86.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.7ms\n",
            "Speed: 0.9ms preprocess, 88.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "161th frame\n",
            "162th frame\n",
            "163th frame\n",
            "164th frame\n",
            "165th frame\n",
            "166th frame\n",
            "167th frame\n",
            "168th frame\n",
            "169th frame\n",
            "170th frame\n",
            "\n",
            "0: 384x640 1 person, 47.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:54.jpg at 2024-03-17 00:05:54.\n",
            "\n",
            "Confidence ---> 0.77\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 47.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 85.7ms\n",
            "Speed: 0.6ms preprocess, 85.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 2 Steel armss, 95.7ms\n",
            "Speed: 0.9ms preprocess, 95.7ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Violence - Weapon Detection - v1 2023-09-11 8-03pm, 93.1ms\n",
            "Speed: 0.9ms preprocess, 93.1ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "171th frame\n",
            "172th frame\n",
            "173th frame\n",
            "174th frame\n",
            "175th frame\n",
            "176th frame\n",
            "177th frame\n",
            "178th frame\n",
            "179th frame\n",
            "180th frame\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 47.5ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:55.jpg at 2024-03-17 00:05:55.\n",
            "\n",
            "Confidence ---> 0.82\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 47.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.1ms\n",
            "Speed: 0.8ms preprocess, 88.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.7ms\n",
            "Speed: 0.8ms preprocess, 89.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Violence - Weapon Detection - v1 2023-09-11 8-03pm, 89.3ms\n",
            "Speed: 1.4ms preprocess, 89.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "181th frame\n",
            "182th frame\n",
            "183th frame\n",
            "184th frame\n",
            "185th frame\n",
            "186th frame\n",
            "187th frame\n",
            "188th frame\n",
            "189th frame\n",
            "190th frame\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 46.7ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:55.jpg at 2024-03-17 00:05:55.\n",
            "\n",
            "Confidence ---> 0.8\n",
            "Class name --> person\n",
            "Speed: 1.3ms preprocess, 46.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.7ms\n",
            "Speed: 0.6ms preprocess, 90.7ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.8ms\n",
            "Speed: 0.9ms preprocess, 89.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Violence - Weapon Detection - v1 2023-09-11 8-03pm, 161.4ms\n",
            "Error: Class index out of range\n",
            "Speed: 0.8ms preprocess, 161.4ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "191th frame\n",
            "192th frame\n",
            "193th frame\n",
            "194th frame\n",
            "195th frame\n",
            "196th frame\n",
            "197th frame\n",
            "198th frame\n",
            "199th frame\n",
            "200th frame\n",
            "\n",
            "0: 384x640 1 person, 49.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:55.jpg at 2024-03-17 00:05:55.\n",
            "\n",
            "Confidence ---> 0.9\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 49.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 91.6ms\n",
            "Speed: 0.9ms preprocess, 91.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Steel arms, 94.2ms\n",
            "Speed: 0.8ms preprocess, 94.2ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Violence - Weapon Detection - v1 2023-09-11 8-03pm, 92.2ms\n",
            "Speed: 0.9ms preprocess, 92.2ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "201th frame\n",
            "202th frame\n",
            "203th frame\n",
            "204th frame\n",
            "205th frame\n",
            "206th frame\n",
            "207th frame\n",
            "208th frame\n",
            "209th frame\n",
            "210th frame\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 47.4ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:56.jpg at 2024-03-17 00:05:56.\n",
            "\n",
            "Confidence ---> 0.9\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.5ms\n",
            "Speed: 0.7ms preprocess, 90.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Rifle, 89.4ms\n",
            "Speed: 0.8ms preprocess, 89.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Violence - Weapon Detection - v1 2023-09-11 8-03pm, 86.8ms\n",
            "Speed: 0.7ms preprocess, 86.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "211th frame\n",
            "212th frame\n",
            "213th frame\n",
            "214th frame\n",
            "215th frame\n",
            "216th frame\n",
            "217th frame\n",
            "218th frame\n",
            "219th frame\n",
            "220th frame\n",
            "\n",
            "0: 384x640 1 person, 48.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:56.jpg at 2024-03-17 00:05:56.\n",
            "\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Speed: 1.3ms preprocess, 48.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 94.4ms\n",
            "Speed: 0.7ms preprocess, 94.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.2ms\n",
            "Speed: 0.8ms preprocess, 89.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 94.3ms\n",
            "Speed: 1.0ms preprocess, 94.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "221th frame\n",
            "222th frame\n",
            "223th frame\n",
            "224th frame\n",
            "225th frame\n",
            "226th frame\n",
            "227th frame\n",
            "228th frame\n",
            "229th frame\n",
            "230th frame\n",
            "\n",
            "0: 384x640 1 person, 56.5ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:56.jpg at 2024-03-17 00:05:56.\n",
            "\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 56.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.7ms\n",
            "Speed: 0.6ms preprocess, 87.7ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.8ms\n",
            "Speed: 0.9ms preprocess, 88.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.6ms\n",
            "Speed: 0.7ms preprocess, 88.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "231th frame\n",
            "232th frame\n",
            "233th frame\n",
            "234th frame\n",
            "235th frame\n",
            "236th frame\n",
            "237th frame\n",
            "238th frame\n",
            "239th frame\n",
            "240th frame\n",
            "\n",
            "0: 384x640 1 person, 47.6ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:57.jpg at 2024-03-17 00:05:57.\n",
            "\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 47.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.8ms\n",
            "Speed: 0.6ms preprocess, 90.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.4ms\n",
            "Speed: 0.8ms preprocess, 88.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.5ms\n",
            "Speed: 0.9ms preprocess, 88.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "241th frame\n",
            "242th frame\n",
            "243th frame\n",
            "244th frame\n",
            "245th frame\n",
            "246th frame\n",
            "247th frame\n",
            "248th frame\n",
            "249th frame\n",
            "250th frame\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 50.1ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:57.jpg at 2024-03-17 00:05:57.\n",
            "\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 50.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 100.0ms\n",
            "Speed: 0.7ms preprocess, 100.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Steel arms, 88.5ms\n",
            "Speed: 0.8ms preprocess, 88.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.2ms\n",
            "Speed: 0.8ms preprocess, 88.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "251th frame\n",
            "252th frame\n",
            "253th frame\n",
            "254th frame\n",
            "255th frame\n",
            "256th frame\n",
            "257th frame\n",
            "258th frame\n",
            "259th frame\n",
            "260th frame\n",
            "\n",
            "0: 384x640 1 person, 1 car, 48.4ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:58.jpg at 2024-03-17 00:05:58.\n",
            "\n",
            "Confidence ---> 0.82\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 48.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.2ms\n",
            "Speed: 0.7ms preprocess, 87.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 2 Handguns, 87.8ms\n",
            "Speed: 1.0ms preprocess, 87.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.8ms\n",
            "Speed: 0.8ms preprocess, 89.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "261th frame\n",
            "262th frame\n",
            "263th frame\n",
            "264th frame\n",
            "265th frame\n",
            "266th frame\n",
            "267th frame\n",
            "268th frame\n",
            "269th frame\n",
            "270th frame\n",
            "\n",
            "0: 384x640 1 person, 58.2ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:58.jpg at 2024-03-17 00:05:58.\n",
            "\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 58.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 110.6ms\n",
            "Speed: 1.0ms preprocess, 110.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Rifle, 108.5ms\n",
            "Speed: 0.8ms preprocess, 108.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 106.7ms\n",
            "Speed: 1.0ms preprocess, 106.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "271th frame\n",
            "272th frame\n",
            "273th frame\n",
            "274th frame\n",
            "275th frame\n",
            "276th frame\n",
            "277th frame\n",
            "278th frame\n",
            "279th frame\n",
            "280th frame\n",
            "\n",
            "0: 384x640 1 person, 55.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:58.jpg at 2024-03-17 00:05:58.\n",
            "\n",
            "Confidence ---> 0.64\n",
            "Class name --> person\n",
            "Speed: 1.4ms preprocess, 55.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 99.3ms\n",
            "Speed: 0.7ms preprocess, 99.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Rifle, 98.7ms\n",
            "Speed: 0.7ms preprocess, 98.7ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 99.0ms\n",
            "Speed: 0.8ms preprocess, 99.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "281th frame\n",
            "282th frame\n",
            "283th frame\n",
            "284th frame\n",
            "285th frame\n",
            "286th frame\n",
            "287th frame\n",
            "288th frame\n",
            "289th frame\n",
            "290th frame\n",
            "\n",
            "0: 384x640 1 person, 54.1ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:59.jpg at 2024-03-17 00:05:59.\n",
            "\n",
            "Confidence ---> 0.81\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 54.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 104.3ms\n",
            "Speed: 0.6ms preprocess, 104.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Handgun, 1 Rifle, 116.8ms\n",
            "Speed: 0.9ms preprocess, 116.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 98.8ms\n",
            "Speed: 0.9ms preprocess, 98.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "291th frame\n",
            "292th frame\n",
            "293th frame\n",
            "294th frame\n",
            "295th frame\n",
            "296th frame\n",
            "297th frame\n",
            "298th frame\n",
            "299th frame\n",
            "300th frame\n",
            "\n",
            "0: 384x640 1 person, 47.3ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:59.jpg at 2024-03-17 00:05:59.\n",
            "\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 47.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.4ms\n",
            "Speed: 0.9ms preprocess, 88.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.4ms\n",
            "Speed: 0.9ms preprocess, 87.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.9ms\n",
            "Speed: 0.9ms preprocess, 91.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "301th frame\n",
            "302th frame\n",
            "303th frame\n",
            "304th frame\n",
            "305th frame\n",
            "306th frame\n",
            "307th frame\n",
            "308th frame\n",
            "309th frame\n",
            "310th frame\n",
            "\n",
            "0: 384x640 1 person, 46.8ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:05:59.jpg at 2024-03-17 00:05:59.\n",
            "\n",
            "Confidence ---> 0.84\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 46.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.4ms\n",
            "Speed: 0.6ms preprocess, 90.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Handgun, 89.8ms\n",
            "Speed: 1.0ms preprocess, 89.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.5ms\n",
            "Speed: 0.7ms preprocess, 85.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "311th frame\n",
            "312th frame\n",
            "313th frame\n",
            "314th frame\n",
            "315th frame\n",
            "316th frame\n",
            "317th frame\n",
            "318th frame\n",
            "319th frame\n",
            "320th frame\n",
            "\n",
            "0: 384x640 1 person, 50.3ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:00.jpg at 2024-03-17 00:06:00.\n",
            "\n",
            "Confidence ---> 0.93\n",
            "Class name --> person\n",
            "Speed: 1.4ms preprocess, 50.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.1ms\n",
            "Speed: 0.7ms preprocess, 88.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 120.3ms\n",
            "Speed: 0.7ms preprocess, 120.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.2ms\n",
            "Speed: 0.7ms preprocess, 89.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "321th frame\n",
            "322th frame\n",
            "323th frame\n",
            "324th frame\n",
            "325th frame\n",
            "326th frame\n",
            "327th frame\n",
            "328th frame\n",
            "329th frame\n",
            "330th frame\n",
            "\n",
            "0: 384x640 1 person, 47.6ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:00.jpg at 2024-03-17 00:06:00.\n",
            "\n",
            "Confidence ---> 0.93\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 47.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 83.9ms\n",
            "Speed: 0.7ms preprocess, 83.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.9ms\n",
            "Speed: 0.7ms preprocess, 90.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.9ms\n",
            "Speed: 1.0ms preprocess, 87.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "331th frame\n",
            "332th frame\n",
            "333th frame\n",
            "334th frame\n",
            "335th frame\n",
            "336th frame\n",
            "337th frame\n",
            "338th frame\n",
            "339th frame\n",
            "340th frame\n",
            "\n",
            "0: 384x640 1 person, 46.7ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:01.jpg at 2024-03-17 00:06:01.\n",
            "\n",
            "Confidence ---> 0.93\n",
            "Class name --> person\n",
            "Speed: 1.2ms preprocess, 46.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 91.3ms\n",
            "Speed: 0.8ms preprocess, 91.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.9ms\n",
            "Speed: 1.0ms preprocess, 86.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.4ms\n",
            "Speed: 0.8ms preprocess, 88.4ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "341th frame\n",
            "342th frame\n",
            "343th frame\n",
            "344th frame\n",
            "345th frame\n",
            "346th frame\n",
            "347th frame\n",
            "348th frame\n",
            "349th frame\n",
            "350th frame\n",
            "\n",
            "0: 384x640 (no detections), 45.8ms\n",
            "Speed: 1.2ms preprocess, 45.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.8ms\n",
            "Speed: 0.9ms preprocess, 87.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.0ms\n",
            "Speed: 0.7ms preprocess, 87.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.4ms\n",
            "Speed: 1.1ms preprocess, 88.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "351th frame\n",
            "352th frame\n",
            "353th frame\n",
            "354th frame\n",
            "355th frame\n",
            "356th frame\n",
            "357th frame\n",
            "358th frame\n",
            "359th frame\n",
            "360th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.6ms\n",
            "Speed: 0.9ms preprocess, 48.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.5ms\n",
            "Speed: 1.3ms preprocess, 89.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.2ms\n",
            "Speed: 0.9ms preprocess, 89.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.0ms\n",
            "Speed: 0.8ms preprocess, 86.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "361th frame\n",
            "362th frame\n",
            "363th frame\n",
            "364th frame\n",
            "365th frame\n",
            "366th frame\n",
            "367th frame\n",
            "368th frame\n",
            "369th frame\n",
            "370th frame\n",
            "\n",
            "0: 384x640 (no detections), 49.1ms\n",
            "Speed: 0.9ms preprocess, 49.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.5ms\n",
            "Speed: 0.9ms preprocess, 87.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 98.2ms\n",
            "Speed: 1.2ms preprocess, 98.2ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.4ms\n",
            "Speed: 1.0ms preprocess, 88.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "371th frame\n",
            "372th frame\n",
            "373th frame\n",
            "374th frame\n",
            "375th frame\n",
            "376th frame\n",
            "377th frame\n",
            "378th frame\n",
            "379th frame\n",
            "380th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.9ms\n",
            "Speed: 0.9ms preprocess, 47.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 86.8ms\n",
            "Speed: 1.1ms preprocess, 86.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 99.8ms\n",
            "Speed: 0.8ms preprocess, 99.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 93.7ms\n",
            "Speed: 0.8ms preprocess, 93.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "381th frame\n",
            "382th frame\n",
            "383th frame\n",
            "384th frame\n",
            "385th frame\n",
            "386th frame\n",
            "387th frame\n",
            "388th frame\n",
            "389th frame\n",
            "390th frame\n",
            "\n",
            "0: 384x640 1 tv, 46.8ms\n",
            "Confidence ---> 0.79\n",
            "Class name --> tvmonitor\n",
            "Speed: 1.3ms preprocess, 46.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.3ms\n",
            "Speed: 0.8ms preprocess, 88.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 107.4ms\n",
            "Speed: 1.2ms preprocess, 107.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 122.0ms\n",
            "Speed: 0.9ms preprocess, 122.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "391th frame\n",
            "392th frame\n",
            "393th frame\n",
            "394th frame\n",
            "395th frame\n",
            "396th frame\n",
            "397th frame\n",
            "398th frame\n",
            "399th frame\n",
            "400th frame\n",
            "\n",
            "0: 384x640 1 tv, 51.3ms\n",
            "Speed: 1.2ms preprocess, 51.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 93.1ms\n",
            "Speed: 1.1ms preprocess, 93.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.4ms\n",
            "Speed: 0.8ms preprocess, 87.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 84.9ms\n",
            "Speed: 0.7ms preprocess, 84.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "401th frame\n",
            "402th frame\n",
            "403th frame\n",
            "404th frame\n",
            "405th frame\n",
            "406th frame\n",
            "407th frame\n",
            "408th frame\n",
            "409th frame\n",
            "410th frame\n",
            "\n",
            "0: 384x640 (no detections), 49.3ms\n",
            "Speed: 1.0ms preprocess, 49.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.1ms\n",
            "Speed: 0.7ms preprocess, 89.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 97.9ms\n",
            "Speed: 0.7ms preprocess, 97.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.3ms\n",
            "Speed: 0.9ms preprocess, 90.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "411th frame\n",
            "412th frame\n",
            "413th frame\n",
            "414th frame\n",
            "415th frame\n",
            "416th frame\n",
            "417th frame\n",
            "418th frame\n",
            "419th frame\n",
            "420th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.7ms\n",
            "Speed: 0.9ms preprocess, 48.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 84.9ms\n",
            "Speed: 1.1ms preprocess, 84.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.4ms\n",
            "Speed: 0.9ms preprocess, 88.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.6ms\n",
            "Speed: 0.8ms preprocess, 85.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "421th frame\n",
            "422th frame\n",
            "423th frame\n",
            "424th frame\n",
            "425th frame\n",
            "426th frame\n",
            "427th frame\n",
            "428th frame\n",
            "429th frame\n",
            "430th frame\n",
            "\n",
            "0: 384x640 (no detections), 45.8ms\n",
            "Speed: 1.0ms preprocess, 45.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 86.6ms\n",
            "Speed: 0.7ms preprocess, 86.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.5ms\n",
            "Speed: 0.9ms preprocess, 87.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 94.3ms\n",
            "Speed: 1.0ms preprocess, 94.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "431th frame\n",
            "432th frame\n",
            "433th frame\n",
            "434th frame\n",
            "435th frame\n",
            "436th frame\n",
            "437th frame\n",
            "438th frame\n",
            "439th frame\n",
            "440th frame\n",
            "\n",
            "0: 384x640 1 tv, 47.4ms\n",
            "Speed: 1.1ms preprocess, 47.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 91.0ms\n",
            "Speed: 1.0ms preprocess, 91.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 97.5ms\n",
            "Speed: 0.6ms preprocess, 97.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 117.5ms\n",
            "Speed: 0.9ms preprocess, 117.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "441th frame\n",
            "442th frame\n",
            "443th frame\n",
            "444th frame\n",
            "445th frame\n",
            "446th frame\n",
            "447th frame\n",
            "448th frame\n",
            "449th frame\n",
            "450th frame\n",
            "\n",
            "0: 384x640 1 tv, 50.4ms\n",
            "Speed: 1.0ms preprocess, 50.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 99.9ms\n",
            "Speed: 0.9ms preprocess, 99.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 92.0ms\n",
            "Speed: 0.9ms preprocess, 92.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.9ms\n",
            "Speed: 0.6ms preprocess, 86.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "451th frame\n",
            "452th frame\n",
            "453th frame\n",
            "454th frame\n",
            "455th frame\n",
            "456th frame\n",
            "457th frame\n",
            "458th frame\n",
            "459th frame\n",
            "460th frame\n",
            "\n",
            "0: 384x640 1 tv, 47.9ms\n",
            "Speed: 1.1ms preprocess, 47.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 92.0ms\n",
            "Speed: 0.8ms preprocess, 92.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 96.9ms\n",
            "Speed: 0.8ms preprocess, 96.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.9ms\n",
            "Speed: 0.8ms preprocess, 91.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "461th frame\n",
            "462th frame\n",
            "463th frame\n",
            "464th frame\n",
            "465th frame\n",
            "466th frame\n",
            "467th frame\n",
            "468th frame\n",
            "469th frame\n",
            "470th frame\n",
            "\n",
            "0: 384x640 1 tv, 49.6ms\n",
            "Speed: 1.0ms preprocess, 49.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 105.0ms\n",
            "Speed: 0.9ms preprocess, 105.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 96.5ms\n",
            "Speed: 0.7ms preprocess, 96.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 93.6ms\n",
            "Speed: 0.8ms preprocess, 93.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "471th frame\n",
            "472th frame\n",
            "473th frame\n",
            "474th frame\n",
            "475th frame\n",
            "476th frame\n",
            "477th frame\n",
            "478th frame\n",
            "479th frame\n",
            "480th frame\n",
            "\n",
            "0: 384x640 1 tv, 46.6ms\n",
            "Speed: 1.0ms preprocess, 46.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.8ms\n",
            "Speed: 0.7ms preprocess, 87.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.2ms\n",
            "Speed: 0.9ms preprocess, 86.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 96.6ms\n",
            "Speed: 0.7ms preprocess, 96.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "481th frame\n",
            "482th frame\n",
            "483th frame\n",
            "484th frame\n",
            "485th frame\n",
            "486th frame\n",
            "487th frame\n",
            "488th frame\n",
            "489th frame\n",
            "490th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.5ms\n",
            "Speed: 1.0ms preprocess, 48.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.3ms\n",
            "Speed: 0.8ms preprocess, 90.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 94.6ms\n",
            "Speed: 0.9ms preprocess, 94.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 100.5ms\n",
            "Speed: 0.8ms preprocess, 100.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "491th frame\n",
            "492th frame\n",
            "493th frame\n",
            "494th frame\n",
            "495th frame\n",
            "496th frame\n",
            "497th frame\n",
            "498th frame\n",
            "499th frame\n",
            "500th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.6ms\n",
            "Speed: 1.0ms preprocess, 47.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.0ms\n",
            "Speed: 1.0ms preprocess, 87.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.3ms\n",
            "Speed: 0.8ms preprocess, 88.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.8ms\n",
            "Speed: 0.8ms preprocess, 90.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "501th frame\n",
            "502th frame\n",
            "503th frame\n",
            "504th frame\n",
            "505th frame\n",
            "506th frame\n",
            "507th frame\n",
            "508th frame\n",
            "509th frame\n",
            "510th frame\n",
            "\n",
            "0: 384x640 (no detections), 45.4ms\n",
            "Speed: 1.0ms preprocess, 45.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.0ms\n",
            "Speed: 0.6ms preprocess, 87.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.4ms\n",
            "Speed: 0.7ms preprocess, 85.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 83.9ms\n",
            "Speed: 0.8ms preprocess, 83.9ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "511th frame\n",
            "512th frame\n",
            "513th frame\n",
            "514th frame\n",
            "515th frame\n",
            "516th frame\n",
            "517th frame\n",
            "518th frame\n",
            "519th frame\n",
            "520th frame\n",
            "\n",
            "0: 384x640 (no detections), 46.5ms\n",
            "Speed: 1.0ms preprocess, 46.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.8ms\n",
            "Speed: 0.9ms preprocess, 87.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 96.9ms\n",
            "Speed: 0.8ms preprocess, 96.9ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 86.0ms\n",
            "Speed: 1.2ms preprocess, 86.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "521th frame\n",
            "522th frame\n",
            "523th frame\n",
            "524th frame\n",
            "525th frame\n",
            "526th frame\n",
            "527th frame\n",
            "528th frame\n",
            "529th frame\n",
            "530th frame\n",
            "\n",
            "0: 384x640 1 tv, 46.6ms\n",
            "Speed: 1.3ms preprocess, 46.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 99.1ms\n",
            "Speed: 1.1ms preprocess, 99.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 98.9ms\n",
            "Speed: 1.0ms preprocess, 98.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.1ms\n",
            "Speed: 0.8ms preprocess, 90.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "531th frame\n",
            "532th frame\n",
            "533th frame\n",
            "534th frame\n",
            "535th frame\n",
            "536th frame\n",
            "537th frame\n",
            "538th frame\n",
            "539th frame\n",
            "540th frame\n",
            "\n",
            "0: 384x640 (no detections), 46.8ms\n",
            "Speed: 1.1ms preprocess, 46.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.3ms\n",
            "Speed: 0.9ms preprocess, 89.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 96.2ms\n",
            "Speed: 0.8ms preprocess, 96.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 93.9ms\n",
            "Speed: 0.9ms preprocess, 93.9ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "541th frame\n",
            "542th frame\n",
            "543th frame\n",
            "544th frame\n",
            "545th frame\n",
            "546th frame\n",
            "547th frame\n",
            "548th frame\n",
            "549th frame\n",
            "550th frame\n",
            "\n",
            "0: 384x640 (no detections), 50.8ms\n",
            "Speed: 0.9ms preprocess, 50.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 91.9ms\n",
            "Speed: 0.6ms preprocess, 91.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.9ms\n",
            "Speed: 0.9ms preprocess, 91.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.6ms\n",
            "Speed: 0.6ms preprocess, 89.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "551th frame\n",
            "552th frame\n",
            "553th frame\n",
            "554th frame\n",
            "555th frame\n",
            "556th frame\n",
            "557th frame\n",
            "558th frame\n",
            "559th frame\n",
            "560th frame\n",
            "\n",
            "0: 384x640 (no detections), 51.2ms\n",
            "Speed: 1.0ms preprocess, 51.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 118.8ms\n",
            "Speed: 0.7ms preprocess, 118.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 109.4ms\n",
            "Speed: 0.6ms preprocess, 109.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 95.1ms\n",
            "Speed: 0.9ms preprocess, 95.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "561th frame\n",
            "562th frame\n",
            "563th frame\n",
            "564th frame\n",
            "565th frame\n",
            "566th frame\n",
            "567th frame\n",
            "568th frame\n",
            "569th frame\n",
            "570th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.6ms\n",
            "Speed: 1.1ms preprocess, 48.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.5ms\n",
            "Speed: 0.9ms preprocess, 87.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 83.5ms\n",
            "Speed: 1.0ms preprocess, 83.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 109.8ms\n",
            "Speed: 7.2ms preprocess, 109.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "571th frame\n",
            "572th frame\n",
            "573th frame\n",
            "574th frame\n",
            "575th frame\n",
            "576th frame\n",
            "577th frame\n",
            "578th frame\n",
            "579th frame\n",
            "580th frame\n",
            "\n",
            "0: 384x640 1 tv, 48.5ms\n",
            "Speed: 1.0ms preprocess, 48.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.6ms\n",
            "Speed: 0.7ms preprocess, 89.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.8ms\n",
            "Speed: 0.7ms preprocess, 88.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.9ms\n",
            "Speed: 0.8ms preprocess, 87.9ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "581th frame\n",
            "582th frame\n",
            "583th frame\n",
            "584th frame\n",
            "585th frame\n",
            "586th frame\n",
            "587th frame\n",
            "588th frame\n",
            "589th frame\n",
            "590th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.6ms\n",
            "Speed: 0.9ms preprocess, 48.6ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.1ms\n",
            "Speed: 0.9ms preprocess, 89.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.3ms\n",
            "Speed: 0.9ms preprocess, 86.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.8ms\n",
            "Speed: 0.8ms preprocess, 88.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "591th frame\n",
            "592th frame\n",
            "593th frame\n",
            "594th frame\n",
            "595th frame\n",
            "596th frame\n",
            "597th frame\n",
            "598th frame\n",
            "599th frame\n",
            "600th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.1ms\n",
            "Speed: 0.9ms preprocess, 48.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.3ms\n",
            "Speed: 0.6ms preprocess, 88.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 94.9ms\n",
            "Speed: 1.0ms preprocess, 94.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.0ms\n",
            "Speed: 0.8ms preprocess, 86.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "601th frame\n",
            "602th frame\n",
            "603th frame\n",
            "604th frame\n",
            "605th frame\n",
            "606th frame\n",
            "607th frame\n",
            "608th frame\n",
            "609th frame\n",
            "610th frame\n",
            "\n",
            "0: 384x640 (no detections), 49.8ms\n",
            "Speed: 1.2ms preprocess, 49.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 84.5ms\n",
            "Speed: 1.1ms preprocess, 84.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.1ms\n",
            "Speed: 0.8ms preprocess, 87.1ms inference, 0.1ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 88.9ms\n",
            "Speed: 0.8ms preprocess, 88.9ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "611th frame\n",
            "612th frame\n",
            "613th frame\n",
            "614th frame\n",
            "615th frame\n",
            "616th frame\n",
            "617th frame\n",
            "618th frame\n",
            "619th frame\n",
            "620th frame\n",
            "\n",
            "0: 384x640 (no detections), 45.9ms\n",
            "Speed: 1.0ms preprocess, 45.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 92.3ms\n",
            "Speed: 1.0ms preprocess, 92.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.9ms\n",
            "Speed: 0.9ms preprocess, 91.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 89.5ms\n",
            "Speed: 0.8ms preprocess, 89.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "621th frame\n",
            "622th frame\n",
            "623th frame\n",
            "624th frame\n",
            "625th frame\n",
            "626th frame\n",
            "627th frame\n",
            "628th frame\n",
            "629th frame\n",
            "630th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.0ms\n",
            "Speed: 1.3ms preprocess, 47.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 84.8ms\n",
            "Speed: 1.2ms preprocess, 84.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.6ms\n",
            "Speed: 0.8ms preprocess, 87.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 91.3ms\n",
            "Speed: 0.8ms preprocess, 91.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "631th frame\n",
            "632th frame\n",
            "633th frame\n",
            "634th frame\n",
            "635th frame\n",
            "636th frame\n",
            "637th frame\n",
            "638th frame\n",
            "639th frame\n",
            "640th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.7ms\n",
            "Speed: 1.0ms preprocess, 47.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.2ms\n",
            "Speed: 0.7ms preprocess, 89.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.3ms\n",
            "Speed: 0.7ms preprocess, 87.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 86.8ms\n",
            "Speed: 0.8ms preprocess, 86.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "641th frame\n",
            "642th frame\n",
            "643th frame\n",
            "644th frame\n",
            "645th frame\n",
            "646th frame\n",
            "647th frame\n",
            "648th frame\n",
            "649th frame\n",
            "650th frame\n",
            "\n",
            "0: 384x640 (no detections), 46.8ms\n",
            "Speed: 0.9ms preprocess, 46.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 85.7ms\n",
            "Speed: 0.8ms preprocess, 85.7ms inference, 0.1ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.0ms\n",
            "Speed: 0.8ms preprocess, 86.0ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 86.3ms\n",
            "Speed: 0.7ms preprocess, 86.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "651th frame\n",
            "652th frame\n",
            "653th frame\n",
            "654th frame\n",
            "655th frame\n",
            "656th frame\n",
            "657th frame\n",
            "658th frame\n",
            "659th frame\n",
            "660th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.4ms\n",
            "Speed: 0.9ms preprocess, 47.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.0ms\n",
            "Speed: 1.2ms preprocess, 90.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 94.1ms\n",
            "Speed: 0.7ms preprocess, 94.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 87.4ms\n",
            "Speed: 0.6ms preprocess, 87.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "661th frame\n",
            "662th frame\n",
            "663th frame\n",
            "664th frame\n",
            "665th frame\n",
            "666th frame\n",
            "667th frame\n",
            "668th frame\n",
            "669th frame\n",
            "670th frame\n",
            "\n",
            "0: 384x640 (no detections), 72.8ms\n",
            "Speed: 1.0ms preprocess, 72.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.1ms\n",
            "Speed: 0.7ms preprocess, 90.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.0ms\n",
            "Speed: 0.7ms preprocess, 87.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 88.4ms\n",
            "Speed: 0.9ms preprocess, 88.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "671th frame\n",
            "672th frame\n",
            "673th frame\n",
            "674th frame\n",
            "675th frame\n",
            "676th frame\n",
            "677th frame\n",
            "678th frame\n",
            "679th frame\n",
            "680th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.0ms\n",
            "Speed: 1.0ms preprocess, 48.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.1ms\n",
            "Speed: 1.1ms preprocess, 87.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.0ms\n",
            "Speed: 1.0ms preprocess, 89.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 88.5ms\n",
            "Speed: 0.8ms preprocess, 88.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "681th frame\n",
            "682th frame\n",
            "683th frame\n",
            "684th frame\n",
            "685th frame\n",
            "686th frame\n",
            "687th frame\n",
            "688th frame\n",
            "689th frame\n",
            "690th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.8ms\n",
            "Speed: 0.9ms preprocess, 47.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 93.6ms\n",
            "Speed: 0.8ms preprocess, 93.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 92.3ms\n",
            "Speed: 0.8ms preprocess, 92.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 89.8ms\n",
            "Speed: 0.8ms preprocess, 89.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "691th frame\n",
            "692th frame\n",
            "693th frame\n",
            "694th frame\n",
            "695th frame\n",
            "696th frame\n",
            "697th frame\n",
            "698th frame\n",
            "699th frame\n",
            "700th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.9ms\n",
            "Speed: 1.1ms preprocess, 47.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.8ms\n",
            "Speed: 0.8ms preprocess, 89.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.6ms\n",
            "Speed: 0.7ms preprocess, 90.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 89.3ms\n",
            "Speed: 0.8ms preprocess, 89.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "701th frame\n",
            "702th frame\n",
            "703th frame\n",
            "704th frame\n",
            "705th frame\n",
            "706th frame\n",
            "707th frame\n",
            "708th frame\n",
            "709th frame\n",
            "710th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.9ms\n",
            "Speed: 1.0ms preprocess, 47.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.8ms\n",
            "Speed: 0.7ms preprocess, 87.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.7ms\n",
            "Speed: 0.8ms preprocess, 87.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.9ms\n",
            "Speed: 0.9ms preprocess, 88.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "711th frame\n",
            "712th frame\n",
            "713th frame\n",
            "714th frame\n",
            "715th frame\n",
            "716th frame\n",
            "717th frame\n",
            "718th frame\n",
            "719th frame\n",
            "720th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.5ms\n",
            "Speed: 1.0ms preprocess, 48.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.1ms\n",
            "Speed: 0.8ms preprocess, 88.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 97.3ms\n",
            "Speed: 0.8ms preprocess, 97.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 104.0ms\n",
            "Speed: 0.9ms preprocess, 104.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "721th frame\n",
            "722th frame\n",
            "723th frame\n",
            "724th frame\n",
            "725th frame\n",
            "726th frame\n",
            "727th frame\n",
            "728th frame\n",
            "729th frame\n",
            "730th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.1ms\n",
            "Speed: 1.1ms preprocess, 48.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.0ms\n",
            "Speed: 1.2ms preprocess, 90.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.6ms\n",
            "Speed: 0.7ms preprocess, 85.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.4ms\n",
            "Speed: 0.8ms preprocess, 88.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "731th frame\n",
            "732th frame\n",
            "733th frame\n",
            "734th frame\n",
            "735th frame\n",
            "736th frame\n",
            "737th frame\n",
            "738th frame\n",
            "739th frame\n",
            "740th frame\n",
            "\n",
            "0: 384x640 (no detections), 49.7ms\n",
            "Speed: 1.1ms preprocess, 49.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.7ms\n",
            "Speed: 0.9ms preprocess, 87.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.0ms\n",
            "Speed: 0.7ms preprocess, 87.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.0ms\n",
            "Speed: 0.9ms preprocess, 89.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "741th frame\n",
            "742th frame\n",
            "743th frame\n",
            "744th frame\n",
            "745th frame\n",
            "746th frame\n",
            "747th frame\n",
            "748th frame\n",
            "749th frame\n",
            "750th frame\n",
            "\n",
            "0: 384x640 (no detections), 50.1ms\n",
            "Speed: 2.2ms preprocess, 50.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.3ms\n",
            "Speed: 1.0ms preprocess, 90.3ms inference, 0.1ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.8ms\n",
            "Speed: 1.0ms preprocess, 90.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.9ms\n",
            "Speed: 0.7ms preprocess, 87.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "751th frame\n",
            "752th frame\n",
            "753th frame\n",
            "754th frame\n",
            "755th frame\n",
            "756th frame\n",
            "757th frame\n",
            "758th frame\n",
            "759th frame\n",
            "760th frame\n",
            "\n",
            "0: 384x640 (no detections), 49.1ms\n",
            "Speed: 1.1ms preprocess, 49.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 114.6ms\n",
            "Speed: 0.8ms preprocess, 114.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.5ms\n",
            "Speed: 0.8ms preprocess, 90.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.3ms\n",
            "Speed: 0.6ms preprocess, 87.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "761th frame\n",
            "762th frame\n",
            "763th frame\n",
            "764th frame\n",
            "765th frame\n",
            "766th frame\n",
            "767th frame\n",
            "768th frame\n",
            "769th frame\n",
            "770th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.2ms\n",
            "Speed: 1.2ms preprocess, 48.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 93.9ms\n",
            "Speed: 0.9ms preprocess, 93.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Handgun, 89.3ms\n",
            "Speed: 1.0ms preprocess, 89.3ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.1ms\n",
            "Speed: 0.7ms preprocess, 91.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "771th frame\n",
            "772th frame\n",
            "773th frame\n",
            "774th frame\n",
            "775th frame\n",
            "776th frame\n",
            "777th frame\n",
            "778th frame\n",
            "779th frame\n",
            "780th frame\n",
            "\n",
            "0: 384x640 (no detections), 46.3ms\n",
            "Speed: 1.2ms preprocess, 46.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 86.8ms\n",
            "Speed: 0.9ms preprocess, 86.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Handgun, 88.4ms\n",
            "Speed: 0.7ms preprocess, 88.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.0ms\n",
            "Speed: 1.1ms preprocess, 89.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "781th frame\n",
            "782th frame\n",
            "783th frame\n",
            "784th frame\n",
            "785th frame\n",
            "786th frame\n",
            "787th frame\n",
            "788th frame\n",
            "789th frame\n",
            "790th frame\n",
            "\n",
            "0: 384x640 2 persons, 48.4ms\n",
            "Speed: 1.0ms preprocess, 48.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 85.7ms\n",
            "Speed: 0.7ms preprocess, 85.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Handgun, 89.5ms\n",
            "Speed: 0.9ms preprocess, 89.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.5ms\n",
            "Speed: 0.8ms preprocess, 85.5ms inference, 0.1ms postprocess per image at shape (1, 3, 256, 448)\n",
            "791th frame\n",
            "792th frame\n",
            "793th frame\n",
            "794th frame\n",
            "795th frame\n",
            "796th frame\n",
            "797th frame\n",
            "798th frame\n",
            "799th frame\n",
            "800th frame\n",
            "\n",
            "0: 384x640 1 person, 47.5ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:17.jpg at 2024-03-17 00:06:17.\n",
            "\n",
            "Confidence ---> 0.81\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 47.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 91.5ms\n",
            "Speed: 0.6ms preprocess, 91.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 94.6ms\n",
            "Speed: 0.9ms preprocess, 94.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.5ms\n",
            "Speed: 0.9ms preprocess, 87.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "801th frame\n",
            "802th frame\n",
            "803th frame\n",
            "804th frame\n",
            "805th frame\n",
            "806th frame\n",
            "807th frame\n",
            "808th frame\n",
            "809th frame\n",
            "810th frame\n",
            "\n",
            "0: 384x640 2 persons, 48.3ms\n",
            "Speed: 1.2ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.5ms\n",
            "Speed: 0.9ms preprocess, 90.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.4ms\n",
            "Speed: 0.7ms preprocess, 88.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 90.2ms\n",
            "Speed: 0.6ms preprocess, 90.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "811th frame\n",
            "812th frame\n",
            "813th frame\n",
            "814th frame\n",
            "815th frame\n",
            "816th frame\n",
            "817th frame\n",
            "818th frame\n",
            "819th frame\n",
            "820th frame\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 49.8ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:18.jpg at 2024-03-17 00:06:18.\n",
            "\n",
            "Confidence ---> 0.89\n",
            "Class name --> person\n",
            "Confidence ---> 0.69\n",
            "Class name --> backpack\n",
            "Speed: 1.5ms preprocess, 49.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 1 fire - v1 2024-01-12 8-02pm, 90.0ms\n",
            "Speed: 0.8ms preprocess, 90.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.9ms\n",
            "Speed: 0.8ms preprocess, 88.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.9ms\n",
            "Speed: 0.8ms preprocess, 87.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "821th frame\n",
            "822th frame\n",
            "823th frame\n",
            "824th frame\n",
            "825th frame\n",
            "826th frame\n",
            "827th frame\n",
            "828th frame\n",
            "829th frame\n",
            "830th frame\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 46.2ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:18.jpg at 2024-03-17 00:06:18.\n",
            "\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Speed: 1.5ms preprocess, 46.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 85.9ms\n",
            "Speed: 0.6ms preprocess, 85.9ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.2ms\n",
            "Speed: 0.6ms preprocess, 86.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 91.8ms\n",
            "Speed: 1.1ms preprocess, 91.8ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "831th frame\n",
            "832th frame\n",
            "833th frame\n",
            "834th frame\n",
            "835th frame\n",
            "836th frame\n",
            "837th frame\n",
            "838th frame\n",
            "839th frame\n",
            "840th frame\n",
            "\n",
            "0: 384x640 1 person, 47.7ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:19.jpg at 2024-03-17 00:06:19.\n",
            "\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Speed: 1.2ms preprocess, 47.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.1ms\n",
            "Speed: 0.7ms preprocess, 89.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 116.8ms\n",
            "Speed: 0.8ms preprocess, 116.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 91.6ms\n",
            "Speed: 0.7ms preprocess, 91.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "841th frame\n",
            "842th frame\n",
            "843th frame\n",
            "844th frame\n",
            "845th frame\n",
            "846th frame\n",
            "847th frame\n",
            "848th frame\n",
            "849th frame\n",
            "850th frame\n",
            "\n",
            "0: 384x640 1 person, 46.4ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:19.jpg at 2024-03-17 00:06:19.\n",
            "\n",
            "Confidence ---> 0.91\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 46.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 92.4ms\n",
            "Speed: 0.6ms preprocess, 92.4ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 92.6ms\n",
            "Speed: 0.7ms preprocess, 92.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 91.7ms\n",
            "Speed: 0.6ms preprocess, 91.7ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "851th frame\n",
            "852th frame\n",
            "853th frame\n",
            "854th frame\n",
            "855th frame\n",
            "856th frame\n",
            "857th frame\n",
            "858th frame\n",
            "859th frame\n",
            "860th frame\n",
            "\n",
            "0: 384x640 1 person, 1 refrigerator, 46.2ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:19.jpg at 2024-03-17 00:06:19.\n",
            "\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 46.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.7ms\n",
            "Speed: 0.6ms preprocess, 88.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 94.5ms\n",
            "Speed: 0.9ms preprocess, 94.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.9ms\n",
            "Speed: 0.7ms preprocess, 85.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "861th frame\n",
            "862th frame\n",
            "863th frame\n",
            "864th frame\n",
            "865th frame\n",
            "866th frame\n",
            "867th frame\n",
            "868th frame\n",
            "869th frame\n",
            "870th frame\n",
            "\n",
            "0: 384x640 1 person, 54.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:20.jpg at 2024-03-17 00:06:20.\n",
            "\n",
            "Confidence ---> 0.82\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 54.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 101.7ms\n",
            "Speed: 0.6ms preprocess, 101.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.3ms\n",
            "Speed: 0.7ms preprocess, 88.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.1ms\n",
            "Speed: 0.9ms preprocess, 91.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "871th frame\n",
            "872th frame\n",
            "873th frame\n",
            "874th frame\n",
            "875th frame\n",
            "876th frame\n",
            "877th frame\n",
            "878th frame\n",
            "879th frame\n",
            "880th frame\n",
            "\n",
            "0: 384x640 1 person, 48.2ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:20.jpg at 2024-03-17 00:06:20.\n",
            "\n",
            "Confidence ---> 0.91\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 48.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 84.5ms\n",
            "Speed: 0.6ms preprocess, 84.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.7ms\n",
            "Speed: 0.8ms preprocess, 88.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 87.0ms\n",
            "Speed: 0.7ms preprocess, 87.0ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "881th frame\n",
            "882th frame\n",
            "883th frame\n",
            "884th frame\n",
            "885th frame\n",
            "886th frame\n",
            "887th frame\n",
            "888th frame\n",
            "889th frame\n",
            "890th frame\n",
            "\n",
            "0: 384x640 1 person, 46.4ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:20.jpg at 2024-03-17 00:06:20.\n",
            "\n",
            "Confidence ---> 0.81\n",
            "Class name --> person\n",
            "Speed: 1.2ms preprocess, 46.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.6ms\n",
            "Speed: 0.6ms preprocess, 89.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.6ms\n",
            "Speed: 0.8ms preprocess, 89.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.7ms\n",
            "Speed: 0.8ms preprocess, 91.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "891th frame\n",
            "892th frame\n",
            "893th frame\n",
            "894th frame\n",
            "895th frame\n",
            "896th frame\n",
            "897th frame\n",
            "898th frame\n",
            "899th frame\n",
            "900th frame\n",
            "\n",
            "0: 384x640 1 person, 58.5ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:21.jpg at 2024-03-17 00:06:21.\n",
            "\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Speed: 1.3ms preprocess, 58.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.0ms\n",
            "Speed: 0.7ms preprocess, 89.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Rifle, 91.2ms\n",
            "Speed: 0.8ms preprocess, 91.2ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.9ms\n",
            "Speed: 0.8ms preprocess, 91.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "901th frame\n",
            "902th frame\n",
            "903th frame\n",
            "904th frame\n",
            "905th frame\n",
            "906th frame\n",
            "907th frame\n",
            "908th frame\n",
            "909th frame\n",
            "910th frame\n",
            "\n",
            "0: 384x640 1 person, 46.3ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:21.jpg at 2024-03-17 00:06:21.\n",
            "\n",
            "Confidence ---> 0.76\n",
            "Class name --> person\n",
            "Speed: 1.4ms preprocess, 46.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 91.0ms\n",
            "Speed: 0.7ms preprocess, 91.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 84.3ms\n",
            "Speed: 0.7ms preprocess, 84.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 124.1ms\n",
            "Speed: 0.9ms preprocess, 124.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "911th frame\n",
            "912th frame\n",
            "913th frame\n",
            "914th frame\n",
            "915th frame\n",
            "916th frame\n",
            "917th frame\n",
            "918th frame\n",
            "919th frame\n",
            "920th frame\n",
            "\n",
            "0: 384x640 1 person, 46.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:22.jpg at 2024-03-17 00:06:22.\n",
            "\n",
            "Confidence ---> 0.83\n",
            "Class name --> person\n",
            "Speed: 1.4ms preprocess, 46.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 92.4ms\n",
            "Speed: 0.6ms preprocess, 92.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.3ms\n",
            "Speed: 0.8ms preprocess, 89.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.5ms\n",
            "Speed: 0.8ms preprocess, 87.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "921th frame\n",
            "922th frame\n",
            "923th frame\n",
            "924th frame\n",
            "925th frame\n",
            "926th frame\n",
            "927th frame\n",
            "928th frame\n",
            "929th frame\n",
            "930th frame\n",
            "\n",
            "0: 384x640 1 person, 48.4ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:22.jpg at 2024-03-17 00:06:22.\n",
            "\n",
            "Confidence ---> 0.76\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 48.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.7ms\n",
            "Speed: 0.7ms preprocess, 87.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.8ms\n",
            "Speed: 0.9ms preprocess, 89.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.9ms\n",
            "Speed: 0.7ms preprocess, 86.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "931th frame\n",
            "932th frame\n",
            "933th frame\n",
            "934th frame\n",
            "935th frame\n",
            "936th frame\n",
            "937th frame\n",
            "938th frame\n",
            "939th frame\n",
            "940th frame\n",
            "\n",
            "0: 384x640 1 person, 50.4ms\n",
            "Speed: 0.9ms preprocess, 50.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 103.8ms\n",
            "Speed: 0.9ms preprocess, 103.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Rifle, 93.5ms\n",
            "Speed: 0.8ms preprocess, 93.5ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.6ms\n",
            "Speed: 0.7ms preprocess, 87.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "941th frame\n",
            "942th frame\n",
            "943th frame\n",
            "944th frame\n",
            "945th frame\n",
            "946th frame\n",
            "947th frame\n",
            "948th frame\n",
            "949th frame\n",
            "950th frame\n",
            "\n",
            "0: 384x640 1 person, 46.4ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:23.jpg at 2024-03-17 00:06:23.\n",
            "\n",
            "Confidence ---> 0.88\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 46.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 92.4ms\n",
            "Speed: 0.6ms preprocess, 92.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.8ms\n",
            "Speed: 0.8ms preprocess, 87.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.3ms\n",
            "Speed: 0.9ms preprocess, 88.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "951th frame\n",
            "952th frame\n",
            "953th frame\n",
            "954th frame\n",
            "955th frame\n",
            "956th frame\n",
            "957th frame\n",
            "958th frame\n",
            "959th frame\n",
            "960th frame\n",
            "\n",
            "0: 384x640 1 person, 47.3ms\n",
            "Speed: 0.9ms preprocess, 47.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.6ms\n",
            "Speed: 0.9ms preprocess, 88.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.2ms\n",
            "Speed: 0.8ms preprocess, 89.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 138.8ms\n",
            "Speed: 1.1ms preprocess, 138.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "961th frame\n",
            "962th frame\n",
            "963th frame\n",
            "964th frame\n",
            "965th frame\n",
            "966th frame\n",
            "967th frame\n",
            "968th frame\n",
            "969th frame\n",
            "970th frame\n",
            "\n",
            "0: 384x640 1 person, 47.4ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:23.jpg at 2024-03-17 00:06:23.\n",
            "\n",
            "Confidence ---> 0.8\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 47.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 95.0ms\n",
            "Speed: 0.6ms preprocess, 95.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.2ms\n",
            "Speed: 0.8ms preprocess, 88.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.4ms\n",
            "Speed: 1.3ms preprocess, 91.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "971th frame\n",
            "972th frame\n",
            "973th frame\n",
            "974th frame\n",
            "975th frame\n",
            "976th frame\n",
            "977th frame\n",
            "978th frame\n",
            "979th frame\n",
            "980th frame\n",
            "\n",
            "0: 384x640 1 person, 60.6ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:24.jpg at 2024-03-17 00:06:24.\n",
            "\n",
            "Confidence ---> 0.9\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 60.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 92.1ms\n",
            "Speed: 0.6ms preprocess, 92.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.4ms\n",
            "Speed: 0.6ms preprocess, 88.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 116.2ms\n",
            "Speed: 0.8ms preprocess, 116.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "981th frame\n",
            "982th frame\n",
            "983th frame\n",
            "984th frame\n",
            "985th frame\n",
            "986th frame\n",
            "987th frame\n",
            "988th frame\n",
            "989th frame\n",
            "990th frame\n",
            "\n",
            "0: 384x640 1 person, 48.7ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:24.jpg at 2024-03-17 00:06:24.\n",
            "\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 48.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 98.9ms\n",
            "Speed: 0.7ms preprocess, 98.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.1ms\n",
            "Speed: 0.9ms preprocess, 86.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.3ms\n",
            "Speed: 0.9ms preprocess, 88.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "991th frame\n",
            "992th frame\n",
            "993th frame\n",
            "994th frame\n",
            "995th frame\n",
            "996th frame\n",
            "997th frame\n",
            "998th frame\n",
            "999th frame\n",
            "1000th frame\n",
            "\n",
            "0: 384x640 1 person, 50.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:24.jpg at 2024-03-17 00:06:24.\n",
            "\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 50.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 107.0ms\n",
            "Speed: 0.7ms preprocess, 107.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 98.9ms\n",
            "Speed: 0.9ms preprocess, 98.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.7ms\n",
            "Speed: 0.9ms preprocess, 88.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1001th frame\n",
            "1002th frame\n",
            "1003th frame\n",
            "1004th frame\n",
            "1005th frame\n",
            "1006th frame\n",
            "1007th frame\n",
            "1008th frame\n",
            "1009th frame\n",
            "1010th frame\n",
            "\n",
            "0: 384x640 1 person, 46.1ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:25.jpg at 2024-03-17 00:06:25.\n",
            "\n",
            "Confidence ---> 0.85\n",
            "Class name --> person\n",
            "Speed: 1.2ms preprocess, 46.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.6ms\n",
            "Speed: 0.9ms preprocess, 90.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.8ms\n",
            "Speed: 0.7ms preprocess, 88.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.0ms\n",
            "Speed: 0.9ms preprocess, 87.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1011th frame\n",
            "1012th frame\n",
            "1013th frame\n",
            "1014th frame\n",
            "1015th frame\n",
            "1016th frame\n",
            "1017th frame\n",
            "1018th frame\n",
            "1019th frame\n",
            "1020th frame\n",
            "\n",
            "0: 384x640 1 person, 50.2ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:25.jpg at 2024-03-17 00:06:25.\n",
            "\n",
            "Confidence ---> 0.82\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 50.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.0ms\n",
            "Speed: 0.6ms preprocess, 87.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.9ms\n",
            "Speed: 0.8ms preprocess, 88.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.6ms\n",
            "Speed: 0.8ms preprocess, 86.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1021th frame\n",
            "1022th frame\n",
            "1023th frame\n",
            "1024th frame\n",
            "1025th frame\n",
            "1026th frame\n",
            "1027th frame\n",
            "1028th frame\n",
            "1029th frame\n",
            "1030th frame\n",
            "\n",
            "0: 384x640 1 person, 49.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:26.jpg at 2024-03-17 00:06:26.\n",
            "\n",
            "Confidence ---> 0.76\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 49.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.0ms\n",
            "Speed: 0.7ms preprocess, 87.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.9ms\n",
            "Speed: 0.8ms preprocess, 88.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.3ms\n",
            "Speed: 0.8ms preprocess, 86.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1031th frame\n",
            "1032th frame\n",
            "1033th frame\n",
            "1034th frame\n",
            "1035th frame\n",
            "1036th frame\n",
            "1037th frame\n",
            "1038th frame\n",
            "1039th frame\n",
            "1040th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.3ms\n",
            "Speed: 0.9ms preprocess, 48.3ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 85.4ms\n",
            "Speed: 0.8ms preprocess, 85.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.7ms\n",
            "Speed: 0.8ms preprocess, 88.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.8ms\n",
            "Speed: 0.9ms preprocess, 90.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1041th frame\n",
            "1042th frame\n",
            "1043th frame\n",
            "1044th frame\n",
            "1045th frame\n",
            "1046th frame\n",
            "1047th frame\n",
            "1048th frame\n",
            "1049th frame\n",
            "1050th frame\n",
            "\n",
            "0: 384x640 (no detections), 50.4ms\n",
            "Speed: 1.1ms preprocess, 50.4ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.1ms\n",
            "Speed: 0.9ms preprocess, 89.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 117.2ms\n",
            "Speed: 0.8ms preprocess, 117.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.7ms\n",
            "Speed: 0.7ms preprocess, 87.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1051th frame\n",
            "1052th frame\n",
            "1053th frame\n",
            "1054th frame\n",
            "1055th frame\n",
            "1056th frame\n",
            "1057th frame\n",
            "1058th frame\n",
            "1059th frame\n",
            "1060th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.1ms\n",
            "Speed: 1.0ms preprocess, 47.1ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.2ms\n",
            "Speed: 0.9ms preprocess, 90.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 95.4ms\n",
            "Speed: 0.8ms preprocess, 95.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.9ms\n",
            "Speed: 0.9ms preprocess, 88.9ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1061th frame\n",
            "1062th frame\n",
            "1063th frame\n",
            "1064th frame\n",
            "1065th frame\n",
            "1066th frame\n",
            "1067th frame\n",
            "1068th frame\n",
            "1069th frame\n",
            "1070th frame\n",
            "\n",
            "0: 384x640 (no detections), 46.8ms\n",
            "Speed: 1.1ms preprocess, 46.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.7ms\n",
            "Speed: 0.8ms preprocess, 89.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 93.7ms\n",
            "Speed: 0.9ms preprocess, 93.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 96.8ms\n",
            "Speed: 0.8ms preprocess, 96.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1071th frame\n",
            "1072th frame\n",
            "1073th frame\n",
            "1074th frame\n",
            "1075th frame\n",
            "1076th frame\n",
            "1077th frame\n",
            "1078th frame\n",
            "1079th frame\n",
            "1080th frame\n",
            "\n",
            "0: 384x640 (no detections), 50.6ms\n",
            "Speed: 1.3ms preprocess, 50.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 107.9ms\n",
            "Speed: 1.1ms preprocess, 107.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.6ms\n",
            "Speed: 0.9ms preprocess, 88.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.2ms\n",
            "Speed: 0.8ms preprocess, 90.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1081th frame\n",
            "1082th frame\n",
            "1083th frame\n",
            "1084th frame\n",
            "1085th frame\n",
            "1086th frame\n",
            "1087th frame\n",
            "1088th frame\n",
            "1089th frame\n",
            "1090th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.5ms\n",
            "Speed: 1.2ms preprocess, 47.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.2ms\n",
            "Speed: 0.6ms preprocess, 90.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.8ms\n",
            "Speed: 0.9ms preprocess, 88.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.6ms\n",
            "Speed: 0.8ms preprocess, 87.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1091th frame\n",
            "1092th frame\n",
            "1093th frame\n",
            "1094th frame\n",
            "1095th frame\n",
            "1096th frame\n",
            "1097th frame\n",
            "1098th frame\n",
            "1099th frame\n",
            "1100th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.5ms\n",
            "Speed: 0.9ms preprocess, 47.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.6ms\n",
            "Speed: 0.8ms preprocess, 87.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.2ms\n",
            "Speed: 0.7ms preprocess, 85.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.5ms\n",
            "Speed: 0.8ms preprocess, 89.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1101th frame\n",
            "1102th frame\n",
            "1103th frame\n",
            "1104th frame\n",
            "1105th frame\n",
            "1106th frame\n",
            "1107th frame\n",
            "1108th frame\n",
            "1109th frame\n",
            "1110th frame\n",
            "\n",
            "0: 384x640 (no detections), 46.7ms\n",
            "Speed: 0.9ms preprocess, 46.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.3ms\n",
            "Speed: 1.0ms preprocess, 89.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 85.6ms\n",
            "Speed: 1.0ms preprocess, 85.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.0ms\n",
            "Speed: 0.6ms preprocess, 87.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1111th frame\n",
            "1112th frame\n",
            "1113th frame\n",
            "1114th frame\n",
            "1115th frame\n",
            "1116th frame\n",
            "1117th frame\n",
            "1118th frame\n",
            "1119th frame\n",
            "1120th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.5ms\n",
            "Speed: 1.3ms preprocess, 47.5ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 105.7ms\n",
            "Speed: 8.6ms preprocess, 105.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 110.8ms\n",
            "Speed: 1.2ms preprocess, 110.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.2ms\n",
            "Speed: 0.7ms preprocess, 89.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1121th frame\n",
            "1122th frame\n",
            "1123th frame\n",
            "1124th frame\n",
            "1125th frame\n",
            "1126th frame\n",
            "1127th frame\n",
            "1128th frame\n",
            "1129th frame\n",
            "1130th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.9ms\n",
            "Speed: 1.6ms preprocess, 47.9ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.8ms\n",
            "Speed: 0.7ms preprocess, 88.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.2ms\n",
            "Speed: 0.8ms preprocess, 86.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.6ms\n",
            "Speed: 0.7ms preprocess, 86.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1131th frame\n",
            "1132th frame\n",
            "1133th frame\n",
            "1134th frame\n",
            "1135th frame\n",
            "1136th frame\n",
            "1137th frame\n",
            "1138th frame\n",
            "1139th frame\n",
            "1140th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.0ms\n",
            "Speed: 1.1ms preprocess, 47.0ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 86.7ms\n",
            "Speed: 1.3ms preprocess, 86.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 102.0ms\n",
            "Speed: 0.9ms preprocess, 102.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 100.1ms\n",
            "Speed: 0.8ms preprocess, 100.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1141th frame\n",
            "1142th frame\n",
            "1143th frame\n",
            "1144th frame\n",
            "1145th frame\n",
            "1146th frame\n",
            "1147th frame\n",
            "1148th frame\n",
            "1149th frame\n",
            "1150th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.8ms\n",
            "Speed: 1.0ms preprocess, 48.8ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.4ms\n",
            "Speed: 0.8ms preprocess, 88.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 92.9ms\n",
            "Speed: 0.8ms preprocess, 92.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 158.2ms\n",
            "Speed: 0.8ms preprocess, 158.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1151th frame\n",
            "1152th frame\n",
            "1153th frame\n",
            "1154th frame\n",
            "1155th frame\n",
            "1156th frame\n",
            "1157th frame\n",
            "1158th frame\n",
            "1159th frame\n",
            "1160th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.9ms\n",
            "Speed: 1.1ms preprocess, 47.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.0ms\n",
            "Speed: 1.0ms preprocess, 90.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.8ms\n",
            "Speed: 0.8ms preprocess, 90.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.2ms\n",
            "Speed: 0.8ms preprocess, 89.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1161th frame\n",
            "1162th frame\n",
            "1163th frame\n",
            "1164th frame\n",
            "1165th frame\n",
            "1166th frame\n",
            "1167th frame\n",
            "1168th frame\n",
            "1169th frame\n",
            "1170th frame\n",
            "\n",
            "0: 384x640 1 person, 48.7ms\n",
            "Speed: 1.1ms preprocess, 48.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.1ms\n",
            "Speed: 0.8ms preprocess, 88.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.4ms\n",
            "Speed: 0.9ms preprocess, 89.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.7ms\n",
            "Speed: 0.9ms preprocess, 87.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1171th frame\n",
            "1172th frame\n",
            "1173th frame\n",
            "1174th frame\n",
            "1175th frame\n",
            "1176th frame\n",
            "1177th frame\n",
            "1178th frame\n",
            "1179th frame\n",
            "1180th frame\n",
            "\n",
            "0: 384x640 1 person, 48.1ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:31.jpg at 2024-03-17 00:06:31.\n",
            "\n",
            "Confidence ---> 0.78\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 48.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.5ms\n",
            "Speed: 0.6ms preprocess, 90.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 110.1ms\n",
            "Speed: 4.6ms preprocess, 110.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.1ms\n",
            "Speed: 0.9ms preprocess, 88.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1181th frame\n",
            "1182th frame\n",
            "1183th frame\n",
            "1184th frame\n",
            "1185th frame\n",
            "1186th frame\n",
            "1187th frame\n",
            "1188th frame\n",
            "1189th frame\n",
            "1190th frame\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 52.0ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:31.jpg at 2024-03-17 00:06:31.\n",
            "\n",
            "Confidence ---> 0.72\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 52.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.0ms\n",
            "Speed: 1.0ms preprocess, 89.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 123.4ms\n",
            "Speed: 0.8ms preprocess, 123.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 92.1ms\n",
            "Speed: 0.9ms preprocess, 92.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1191th frame\n",
            "1192th frame\n",
            "1193th frame\n",
            "1194th frame\n",
            "1195th frame\n",
            "1196th frame\n",
            "1197th frame\n",
            "1198th frame\n",
            "1199th frame\n",
            "1200th frame\n",
            "\n",
            "0: 384x640 1 person, 48.2ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:32.jpg at 2024-03-17 00:06:32.\n",
            "\n",
            "Confidence ---> 0.78\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 48.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.4ms\n",
            "Speed: 0.6ms preprocess, 89.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 94.2ms\n",
            "Speed: 1.0ms preprocess, 94.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.6ms\n",
            "Speed: 0.7ms preprocess, 89.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1201th frame\n",
            "1202th frame\n",
            "1203th frame\n",
            "1204th frame\n",
            "1205th frame\n",
            "1206th frame\n",
            "1207th frame\n",
            "1208th frame\n",
            "1209th frame\n",
            "1210th frame\n",
            "\n",
            "0: 384x640 1 person, 50.0ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:32.jpg at 2024-03-17 00:06:32.\n",
            "\n",
            "Confidence ---> 0.85\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 50.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 94.9ms\n",
            "Speed: 0.7ms preprocess, 94.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 93.5ms\n",
            "Speed: 0.9ms preprocess, 93.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.1ms\n",
            "Speed: 0.9ms preprocess, 89.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1211th frame\n",
            "1212th frame\n",
            "1213th frame\n",
            "1214th frame\n",
            "1215th frame\n",
            "1216th frame\n",
            "1217th frame\n",
            "1218th frame\n",
            "1219th frame\n",
            "1220th frame\n",
            "\n",
            "0: 384x640 1 person, 51.3ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:33.jpg at 2024-03-17 00:06:33.\n",
            "\n",
            "Confidence ---> 0.8\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 51.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 119.2ms\n",
            "Speed: 0.7ms preprocess, 119.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Rifle, 92.1ms\n",
            "Rifle detected, storing the frame in the database as frames/2024-03-17 00:06:33.jpg at 2024-03-17 00:06:33.\n",
            "\n",
            "Confidence ---> 0.71\n",
            "Class name --> Rifle\n",
            "Speed: 0.9ms preprocess, 92.1ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.2ms\n",
            "Speed: 0.7ms preprocess, 91.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1221th frame\n",
            "1222th frame\n",
            "1223th frame\n",
            "1224th frame\n",
            "1225th frame\n",
            "1226th frame\n",
            "1227th frame\n",
            "1228th frame\n",
            "1229th frame\n",
            "1230th frame\n",
            "\n",
            "0: 384x640 1 person, 47.4ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:33.jpg at 2024-03-17 00:06:33.\n",
            "\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 47.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.3ms\n",
            "Speed: 0.7ms preprocess, 88.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Rifle, 87.6ms\n",
            "Rifle detected, storing the frame in the database as frames/2024-03-17 00:06:33.jpg at 2024-03-17 00:06:33.\n",
            "\n",
            "Confidence ---> 0.69\n",
            "Class name --> Rifle\n",
            "Speed: 0.8ms preprocess, 87.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.9ms\n",
            "Speed: 0.9ms preprocess, 91.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1231th frame\n",
            "1232th frame\n",
            "1233th frame\n",
            "1234th frame\n",
            "1235th frame\n",
            "1236th frame\n",
            "1237th frame\n",
            "1238th frame\n",
            "1239th frame\n",
            "1240th frame\n",
            "\n",
            "0: 384x640 1 person, 66.4ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:33.jpg at 2024-03-17 00:06:33.\n",
            "\n",
            "Confidence ---> 0.85\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 66.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.1ms\n",
            "Speed: 0.6ms preprocess, 87.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Rifle, 94.4ms\n",
            "Speed: 0.6ms preprocess, 94.4ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 116.3ms\n",
            "Speed: 0.8ms preprocess, 116.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1241th frame\n",
            "1242th frame\n",
            "1243th frame\n",
            "1244th frame\n",
            "1245th frame\n",
            "1246th frame\n",
            "1247th frame\n",
            "1248th frame\n",
            "1249th frame\n",
            "1250th frame\n",
            "\n",
            "0: 384x640 1 person, 1 bed, 47.0ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:34.jpg at 2024-03-17 00:06:34.\n",
            "\n",
            "Confidence ---> 0.86\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 47.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 92.7ms\n",
            "Speed: 1.0ms preprocess, 92.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Rifle, 88.1ms\n",
            "Speed: 0.8ms preprocess, 88.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.3ms\n",
            "Speed: 0.9ms preprocess, 87.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1251th frame\n",
            "1252th frame\n",
            "1253th frame\n",
            "1254th frame\n",
            "1255th frame\n",
            "1256th frame\n",
            "1257th frame\n",
            "1258th frame\n",
            "1259th frame\n",
            "1260th frame\n",
            "\n",
            "0: 384x640 1 person, 47.7ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:34.jpg at 2024-03-17 00:06:34.\n",
            "\n",
            "Confidence ---> 0.81\n",
            "Class name --> person\n",
            "Speed: 1.2ms preprocess, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 92.5ms\n",
            "Speed: 0.7ms preprocess, 92.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.9ms\n",
            "Speed: 1.1ms preprocess, 88.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.3ms\n",
            "Speed: 0.9ms preprocess, 88.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1261th frame\n",
            "1262th frame\n",
            "1263th frame\n",
            "1264th frame\n",
            "1265th frame\n",
            "1266th frame\n",
            "1267th frame\n",
            "1268th frame\n",
            "1269th frame\n",
            "1270th frame\n",
            "\n",
            "0: 384x640 1 person, 1 refrigerator, 48.1ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:34.jpg at 2024-03-17 00:06:34.\n",
            "\n",
            "Confidence ---> 0.87\n",
            "Class name --> person\n",
            "Speed: 1.2ms preprocess, 48.1ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.4ms\n",
            "Speed: 0.6ms preprocess, 90.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 84.8ms\n",
            "Speed: 0.9ms preprocess, 84.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 92.4ms\n",
            "Speed: 0.8ms preprocess, 92.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1271th frame\n",
            "1272th frame\n",
            "1273th frame\n",
            "1274th frame\n",
            "1275th frame\n",
            "1276th frame\n",
            "1277th frame\n",
            "1278th frame\n",
            "1279th frame\n",
            "1280th frame\n",
            "\n",
            "0: 384x640 1 person, 47.8ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:35.jpg at 2024-03-17 00:06:35.\n",
            "\n",
            "Confidence ---> 0.75\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 47.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 91.7ms\n",
            "Speed: 0.7ms preprocess, 91.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.2ms\n",
            "Speed: 0.6ms preprocess, 89.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 3, 87.6ms\n",
            "Speed: 0.9ms preprocess, 87.6ms inference, 0.3ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1281th frame\n",
            "1282th frame\n",
            "1283th frame\n",
            "1284th frame\n",
            "1285th frame\n",
            "1286th frame\n",
            "1287th frame\n",
            "1288th frame\n",
            "1289th frame\n",
            "1290th frame\n",
            "\n",
            "0: 384x640 1 person, 1 refrigerator, 52.3ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:35.jpg at 2024-03-17 00:06:35.\n",
            "\n",
            "Confidence ---> 0.75\n",
            "Class name --> person\n",
            "Speed: 1.3ms preprocess, 52.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 93.5ms\n",
            "Speed: 0.7ms preprocess, 93.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.4ms\n",
            "Speed: 0.8ms preprocess, 91.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 93.8ms\n",
            "Speed: 0.8ms preprocess, 93.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1291th frame\n",
            "1292th frame\n",
            "1293th frame\n",
            "1294th frame\n",
            "1295th frame\n",
            "1296th frame\n",
            "1297th frame\n",
            "1298th frame\n",
            "1299th frame\n",
            "1300th frame\n",
            "\n",
            "0: 384x640 1 person, 80.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:36.jpg at 2024-03-17 00:06:36.\n",
            "\n",
            "Confidence ---> 0.69\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 80.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 98.3ms\n",
            "Speed: 0.7ms preprocess, 98.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 92.8ms\n",
            "Speed: 0.7ms preprocess, 92.8ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 100.7ms\n",
            "Speed: 0.7ms preprocess, 100.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1301th frame\n",
            "1302th frame\n",
            "1303th frame\n",
            "1304th frame\n",
            "1305th frame\n",
            "1306th frame\n",
            "1307th frame\n",
            "1308th frame\n",
            "1309th frame\n",
            "1310th frame\n",
            "\n",
            "0: 384x640 1 person, 55.2ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:36.jpg at 2024-03-17 00:06:36.\n",
            "\n",
            "Confidence ---> 0.63\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 55.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 118.0ms\n",
            "Speed: 0.8ms preprocess, 118.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 118.9ms\n",
            "Speed: 0.7ms preprocess, 118.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 102.8ms\n",
            "Speed: 1.0ms preprocess, 102.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1311th frame\n",
            "1312th frame\n",
            "1313th frame\n",
            "1314th frame\n",
            "1315th frame\n",
            "1316th frame\n",
            "1317th frame\n",
            "1318th frame\n",
            "1319th frame\n",
            "1320th frame\n",
            "\n",
            "0: 384x640 1 person, 54.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:36.jpg at 2024-03-17 00:06:36.\n",
            "\n",
            "Confidence ---> 0.71\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 54.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 106.9ms\n",
            "Speed: 0.7ms preprocess, 106.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 101.7ms\n",
            "Speed: 0.8ms preprocess, 101.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 98.8ms\n",
            "Speed: 0.8ms preprocess, 98.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1321th frame\n",
            "1322th frame\n",
            "1323th frame\n",
            "1324th frame\n",
            "1325th frame\n",
            "1326th frame\n",
            "1327th frame\n",
            "1328th frame\n",
            "1329th frame\n",
            "1330th frame\n",
            "\n",
            "0: 384x640 1 person, 56.6ms\n",
            "Speed: 1.2ms preprocess, 56.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 108.9ms\n",
            "Speed: 0.8ms preprocess, 108.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 98.5ms\n",
            "Speed: 0.7ms preprocess, 98.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 116.9ms\n",
            "Speed: 0.8ms preprocess, 116.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1331th frame\n",
            "1332th frame\n",
            "1333th frame\n",
            "1334th frame\n",
            "1335th frame\n",
            "1336th frame\n",
            "1337th frame\n",
            "1338th frame\n",
            "1339th frame\n",
            "1340th frame\n",
            "\n",
            "0: 384x640 1 person, 58.0ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:37.jpg at 2024-03-17 00:06:37.\n",
            "\n",
            "Confidence ---> 0.62\n",
            "Class name --> person\n",
            "Speed: 3.3ms preprocess, 58.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 104.1ms\n",
            "Speed: 0.6ms preprocess, 104.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.3ms\n",
            "Speed: 0.8ms preprocess, 89.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.1ms\n",
            "Speed: 1.3ms preprocess, 87.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1341th frame\n",
            "1342th frame\n",
            "1343th frame\n",
            "1344th frame\n",
            "1345th frame\n",
            "1346th frame\n",
            "1347th frame\n",
            "1348th frame\n",
            "1349th frame\n",
            "1350th frame\n",
            "\n",
            "0: 384x640 1 person, 47.4ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:38.jpg at 2024-03-17 00:06:38.\n",
            "\n",
            "Confidence ---> 0.76\n",
            "Class name --> person\n",
            "Speed: 1.2ms preprocess, 47.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 95.7ms\n",
            "Speed: 0.8ms preprocess, 95.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 107.4ms\n",
            "Speed: 1.0ms preprocess, 107.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 117.4ms\n",
            "Speed: 0.9ms preprocess, 117.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1351th frame\n",
            "1352th frame\n",
            "1353th frame\n",
            "1354th frame\n",
            "1355th frame\n",
            "1356th frame\n",
            "1357th frame\n",
            "1358th frame\n",
            "1359th frame\n",
            "1360th frame\n",
            "\n",
            "0: 384x640 1 tv, 1 laptop, 49.1ms\n",
            "Speed: 1.0ms preprocess, 49.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.1ms\n",
            "Speed: 0.8ms preprocess, 89.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.8ms\n",
            "Speed: 1.1ms preprocess, 89.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.6ms\n",
            "Speed: 1.0ms preprocess, 89.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1361th frame\n",
            "1362th frame\n",
            "1363th frame\n",
            "1364th frame\n",
            "1365th frame\n",
            "1366th frame\n",
            "1367th frame\n",
            "1368th frame\n",
            "1369th frame\n",
            "1370th frame\n",
            "\n",
            "0: 384x640 1 tv, 1 laptop, 48.4ms\n",
            "Speed: 1.1ms preprocess, 48.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 87.5ms\n",
            "Speed: 0.9ms preprocess, 87.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.1ms\n",
            "Speed: 0.8ms preprocess, 90.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.5ms\n",
            "Speed: 1.1ms preprocess, 90.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1371th frame\n",
            "1372th frame\n",
            "1373th frame\n",
            "1374th frame\n",
            "1375th frame\n",
            "1376th frame\n",
            "1377th frame\n",
            "1378th frame\n",
            "1379th frame\n",
            "1380th frame\n",
            "\n",
            "0: 384x640 1 tv, 1 laptop, 1 oven, 49.7ms\n",
            "Speed: 1.4ms preprocess, 49.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 98.8ms\n",
            "Speed: 0.8ms preprocess, 98.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.5ms\n",
            "Speed: 0.8ms preprocess, 91.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 94.6ms\n",
            "Speed: 1.0ms preprocess, 94.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1381th frame\n",
            "1382th frame\n",
            "1383th frame\n",
            "1384th frame\n",
            "1385th frame\n",
            "1386th frame\n",
            "1387th frame\n",
            "1388th frame\n",
            "1389th frame\n",
            "1390th frame\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 1 laptop, 1 oven, 47.7ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:39.jpg at 2024-03-17 00:06:39.\n",
            "\n",
            "Confidence ---> 0.64\n",
            "Class name --> person\n",
            "Speed: 0.9ms preprocess, 47.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.0ms\n",
            "Speed: 0.7ms preprocess, 89.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 86.3ms\n",
            "Speed: 0.9ms preprocess, 86.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.8ms\n",
            "Speed: 0.9ms preprocess, 89.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1391th frame\n",
            "1392th frame\n",
            "1393th frame\n",
            "1394th frame\n",
            "1395th frame\n",
            "1396th frame\n",
            "1397th frame\n",
            "1398th frame\n",
            "1399th frame\n",
            "1400th frame\n",
            "\n",
            "0: 384x640 1 person, 1 laptop, 1 oven, 49.1ms\n",
            "Speed: 1.3ms preprocess, 49.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.0ms\n",
            "Speed: 1.2ms preprocess, 90.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 1 Grenade, 88.9ms\n",
            "Grenade detected, storing the frame in the database as frames/2024-03-17 00:06:40.jpg at 2024-03-17 00:06:40.\n",
            "\n",
            "Confidence ---> 0.64\n",
            "Class name --> Grenade\n",
            "Speed: 0.8ms preprocess, 88.9ms inference, 0.5ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 139.5ms\n",
            "Speed: 0.8ms preprocess, 139.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1401th frame\n",
            "1402th frame\n",
            "1403th frame\n",
            "1404th frame\n",
            "1405th frame\n",
            "1406th frame\n",
            "1407th frame\n",
            "1408th frame\n",
            "1409th frame\n",
            "1410th frame\n",
            "\n",
            "0: 384x640 1 person, 1 laptop, 1 oven, 50.9ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:40.jpg at 2024-03-17 00:06:40.\n",
            "\n",
            "Confidence ---> 0.73\n",
            "Class name --> person\n",
            "Speed: 1.1ms preprocess, 50.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 95.5ms\n",
            "Speed: 0.7ms preprocess, 95.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 93.5ms\n",
            "Speed: 0.8ms preprocess, 93.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 95.6ms\n",
            "Speed: 0.9ms preprocess, 95.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1411th frame\n",
            "1412th frame\n",
            "1413th frame\n",
            "1414th frame\n",
            "1415th frame\n",
            "1416th frame\n",
            "1417th frame\n",
            "1418th frame\n",
            "1419th frame\n",
            "1420th frame\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 1 laptop, 1 oven, 51.0ms\n",
            "person detected, storing the frame in the database as frames/2024-03-17 00:06:40.jpg at 2024-03-17 00:06:40.\n",
            "\n",
            "Confidence ---> 0.65\n",
            "Class name --> person\n",
            "Speed: 1.0ms preprocess, 51.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 91.4ms\n",
            "Speed: 0.7ms preprocess, 91.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 93.3ms\n",
            "Speed: 0.9ms preprocess, 93.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.7ms\n",
            "Speed: 1.0ms preprocess, 90.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1421th frame\n",
            "1422th frame\n",
            "1423th frame\n",
            "1424th frame\n",
            "1425th frame\n",
            "1426th frame\n",
            "1427th frame\n",
            "1428th frame\n",
            "1429th frame\n",
            "1430th frame\n",
            "\n",
            "0: 384x640 1 dog, 1 tv, 1 laptop, 48.5ms\n",
            "Speed: 1.0ms preprocess, 48.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 91.0ms\n",
            "Speed: 0.8ms preprocess, 91.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.6ms\n",
            "Speed: 0.7ms preprocess, 91.6ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.4ms\n",
            "Speed: 0.8ms preprocess, 89.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1431th frame\n",
            "1432th frame\n",
            "1433th frame\n",
            "1434th frame\n",
            "1435th frame\n",
            "1436th frame\n",
            "1437th frame\n",
            "1438th frame\n",
            "1439th frame\n",
            "1440th frame\n",
            "\n",
            "0: 384x640 1 person, 1 tv, 48.8ms\n",
            "Speed: 1.4ms preprocess, 48.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.0ms\n",
            "Speed: 1.1ms preprocess, 89.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 91.0ms\n",
            "Speed: 1.0ms preprocess, 91.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.4ms\n",
            "Speed: 0.9ms preprocess, 89.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1441th frame\n",
            "1442th frame\n",
            "1443th frame\n",
            "1444th frame\n",
            "1445th frame\n",
            "1446th frame\n",
            "1447th frame\n",
            "1448th frame\n",
            "1449th frame\n",
            "1450th frame\n",
            "\n",
            "0: 384x640 1 laptop, 49.8ms\n",
            "Speed: 1.4ms preprocess, 49.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 97.0ms\n",
            "Speed: 0.9ms preprocess, 97.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.2ms\n",
            "Speed: 1.0ms preprocess, 87.2ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 92.9ms\n",
            "Speed: 0.9ms preprocess, 92.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1451th frame\n",
            "1452th frame\n",
            "1453th frame\n",
            "1454th frame\n",
            "1455th frame\n",
            "1456th frame\n",
            "1457th frame\n",
            "1458th frame\n",
            "1459th frame\n",
            "1460th frame\n",
            "\n",
            "0: 384x640 1 tv, 1 laptop, 76.9ms\n",
            "Speed: 1.2ms preprocess, 76.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 88.1ms\n",
            "Speed: 0.9ms preprocess, 88.1ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 87.8ms\n",
            "Speed: 0.7ms preprocess, 87.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 92.3ms\n",
            "Speed: 1.0ms preprocess, 92.3ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1461th frame\n",
            "1462th frame\n",
            "1463th frame\n",
            "1464th frame\n",
            "1465th frame\n",
            "1466th frame\n",
            "1467th frame\n",
            "1468th frame\n",
            "1469th frame\n",
            "1470th frame\n",
            "\n",
            "0: 384x640 (no detections), 48.7ms\n",
            "Speed: 1.0ms preprocess, 48.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.0ms\n",
            "Speed: 1.0ms preprocess, 89.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.7ms\n",
            "Speed: 1.0ms preprocess, 88.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 98.4ms\n",
            "Speed: 1.1ms preprocess, 98.4ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1471th frame\n",
            "1472th frame\n",
            "1473th frame\n",
            "1474th frame\n",
            "1475th frame\n",
            "1476th frame\n",
            "1477th frame\n",
            "1478th frame\n",
            "1479th frame\n",
            "1480th frame\n",
            "\n",
            "0: 384x640 (no detections), 47.9ms\n",
            "Speed: 1.0ms preprocess, 47.9ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 90.4ms\n",
            "Speed: 0.9ms preprocess, 90.4ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.8ms\n",
            "Speed: 0.7ms preprocess, 88.8ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.5ms\n",
            "Speed: 1.0ms preprocess, 88.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1481th frame\n",
            "1482th frame\n",
            "1483th frame\n",
            "1484th frame\n",
            "1485th frame\n",
            "1486th frame\n",
            "1487th frame\n",
            "1488th frame\n",
            "1489th frame\n",
            "1490th frame\n",
            "\n",
            "0: 384x640 2 persons, 1 laptop, 47.5ms\n",
            "Speed: 1.3ms preprocess, 47.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 89.9ms\n",
            "Speed: 1.0ms preprocess, 89.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 89.1ms\n",
            "Speed: 0.8ms preprocess, 89.1ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.5ms\n",
            "Speed: 1.1ms preprocess, 88.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1491th frame\n",
            "1492th frame\n",
            "1493th frame\n",
            "1494th frame\n",
            "1495th frame\n",
            "1496th frame\n",
            "1497th frame\n",
            "1498th frame\n",
            "1499th frame\n",
            "1500th frame\n",
            "\n",
            "0: 384x640 1 person, 49.2ms\n",
            "Speed: 1.2ms preprocess, 49.2ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 86.5ms\n",
            "Speed: 1.1ms preprocess, 86.5ms inference, 0.4ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 88.7ms\n",
            "Speed: 1.0ms preprocess, 88.7ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 93.2ms\n",
            "Speed: 1.0ms preprocess, 93.2ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1501th frame\n",
            "1502th frame\n",
            "1503th frame\n",
            "1504th frame\n",
            "1505th frame\n",
            "1506th frame\n",
            "1507th frame\n",
            "1508th frame\n",
            "1509th frame\n",
            "1510th frame\n",
            "\n",
            "0: 384x640 1 laptop, 76.9ms\n",
            "Speed: 1.3ms preprocess, 76.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 256x448 (no detections), 94.0ms\n",
            "Speed: 0.7ms preprocess, 94.0ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 90.5ms\n",
            "Speed: 0.7ms preprocess, 90.5ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "\n",
            "0: 256x448 (no detections), 104.9ms\n",
            "Speed: 0.7ms preprocess, 104.9ms inference, 0.2ms postprocess per image at shape (1, 3, 256, 448)\n",
            "1511th frame\n",
            "1512th frame\n",
            "1513th frame\n",
            "1514th frame\n",
            "1515th frame\n",
            "1516th frame\n",
            "1517th frame\n",
            "1518th frame\n",
            "1519th frame\n",
            "1520th frame\n",
            "Error: Unable to capture frame\n"
          ]
        }
      ],
      "source": [
        "start_demo(models, classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lida\n",
        "from lida import llm, Manager, TextGenerationConfig\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = \"hk305qjjFaCIXME1dGS0OIIHDth4NFnTtuzpPCOg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Goal(question='What is the distribution of anomalies by type?', visualization='Histogram of Type of anomaly', rationale='Visualizing the variety of anomalies can help you recognize anomaly trends and respond appropriately. Whether there are many photo anomalies and few person anomalies, a histogram can reveal these patterns ', index=0)\n",
            "Goal(question='Are there any significant time differences between different types of anomalies?', visualization='Box plot of Timestamp by Type of anomaly', rationale='This will help you detect significant variations in timing. You could also note trends in early detection of anomalies to maximize response time', index=1)\n"
          ]
        }
      ],
      "source": [
        "# Load your data (replace with your data source)\n",
        "data = pd.read_csv(\"anomalies.csv\")\n",
        "\n",
        "lida = Manager(text_gen=llm(\"cohere\"))  # Assuming llm is a function to create a LLM object\n",
        "textgen_config = TextGenerationConfig(n=2, temperature=0.5, use_cache=True)  # Set n to 2 for 2 goals\n",
        "\n",
        "try:\n",
        "    # Summarize data with default method\n",
        "    textgen_config.n = 1  # Set n to 1 for a single summary\n",
        "    summary = lida.summarize(data=data, summary_method=\"default\", textgen_config=textgen_config)\n",
        "\n",
        "    # Define security guard persona\n",
        "    persona = \"I am a security guard at a prison. I want to be able to identify and respond to potential threats effectively based on prison anomaly data.\"\n",
        "\n",
        "    # Generate goals based on summary and persona\n",
        "    personal_goals = lida.goals(summary, n=2, persona=persona, textgen_config=textgen_config)\n",
        "\n",
        "    # Display generated goals\n",
        "    for goal in personal_goals:\n",
        "        print(goal)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ```\n",
            "import matplotlib.pyplot as plt\n",
            "import pandas as pd\n",
            "\n",
            "def plot(data: pd.DataFrame):\n",
            "    # Convert date fields to date types and drop NaT values\n",
            "    data['Timestamp'] = pd.to_datetime(data['Timestamp'], errors='coerce')\n",
            "    data = data[pd.notna(data['Timestamp'])]\n",
            "\n",
            "    # Plot box plot of Timestamp by Type of anomaly\n",
            "    plt.boxplot(data['Timestamp'], labels=data['Type of anomaly'], patch_artist=True)\n",
            "    plt.xlabel('Timestamp')\n",
            "    plt.ylabel('Type of anomaly')\n",
            "    plt.title('Are there any significant time differences between different types of anomalies?')\n",
            "    plt.legend(title='Types of anomalies')\n",
            "    return plt\n",
            "\n",
            "chart = plot(data)\n",
            "```\n",
            "****\n",
            " Dimensions of labels and X must be compatible\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "i = 0\n",
        "library = \"matplotlib\"\n",
        "\n",
        "charts = lida.visualize(summary=summary, goal=goal, textgen_config=textgen_config, library=library)  \n",
        "\n",
        "for chart in charts:\n",
        "    try:\n",
        "        chart.show()\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms.huggingface_hub import HuggingFaceHub\n",
        "from langchain.schema import HumanMessage\n",
        "import os\n",
        "from dotenv import get_key\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = get_key(key_to_get=\"HUGGINGFACEHUB_API_KEY\",dotenv_path=\".env\")\n",
        "\n",
        "# llm = HuggingFaceHub(\n",
        "#     repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "#     task=\"text-generation\",\n",
        "#     model_kwargs={\n",
        "#         \"max_new_tokens\": 512,\n",
        "#         \"top_k\": 30,\n",
        "#         \"temperature\": 0.5,\n",
        "#         \"repetition_penalty\": 1.03,\n",
        "#     },\n",
        "# )\n",
        "mixtral_llm = HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",model_kwargs={\"temperature\":0.3, \"max_length\": 100})\n",
        "\n",
        "def chatwithbot(txt:str):\n",
        "    prompt = PromptTemplate(template= \"You're a helpful security assistant. You've been asked to help authorities. They want to be able to detect securty concerns in the city. They've provided you with a list of anomalies in the city with type of anomaly and timestamp.Answer questions of user from given data. Here's the data:\\n{data}. \\n\\nUSERS QUERY:{input}\", input_variables=[\"data\",\"input\"])\n",
        "\n",
        "    # get the data from anomalies.txt\n",
        "    with open(\"anomalies.txt\", \"r\") as f:\n",
        "        data = f.read()\n",
        "    if len(data) == 0:\n",
        "        data = \"No anomalies detected\"\n",
        "\n",
        "    prompt_template = prompt.format(data=data,input=txt)\n",
        "\n",
        "\n",
        "    chat_model = ChatHuggingFace(llm=mixtral_llm)\n",
        "    messages =[\n",
        "        HumanMessage(prompt_template),\n",
        "    ]\n",
        "\n",
        "    res = chat_model.invoke(messages)\n",
        "    print(res.content)\n",
        "    return res\n",
        "    # res = res[res.find(\"<|assistant|>\")+len(\"<|assistant|>\"):]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def chat():\n",
        "    while True:\n",
        "        txt = input(\"Enter your message: \")\n",
        "        if txt == \"exit\":\n",
        "            break\n",
        "        res = chatwithbot(txt)\n",
        "        print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "ename": "LocalTokenNotFoundError",
          "evalue": "Token is required (`token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLocalTokenNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[28], line 6\u001b[0m, in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m txt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mchatwithbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
            "Cell \u001b[1;32mIn[27], line 34\u001b[0m, in \u001b[0;36mchatwithbot\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m     29\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo anomalies detected\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat(data\u001b[38;5;241m=\u001b[39mdata,\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtxt)\n\u001b[1;32m---> 34\u001b[0m chat_model \u001b[38;5;241m=\u001b[39m \u001b[43mChatHuggingFace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmixtral_llm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m messages \u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     36\u001b[0m     HumanMessage(prompt_template),\n\u001b[0;32m     37\u001b[0m ]\n\u001b[0;32m     39\u001b[0m res \u001b[38;5;241m=\u001b[39m chat_model\u001b[38;5;241m.\u001b[39minvoke(messages)\n",
            "File \u001b[1;32me:\\Model-Misfit\\new-venv\\Lib\\site-packages\\langchain_community\\chat_models\\huggingface.py:54\u001b[0m, in \u001b[0;36mChatHuggingFace.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve_model_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     57\u001b[0m     AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id)\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\n\u001b[0;32m     60\u001b[0m )\n",
            "File \u001b[1;32me:\\Model-Misfit\\new-venv\\Lib\\site-packages\\langchain_community\\chat_models\\huggingface.py:150\u001b[0m, in \u001b[0;36mChatHuggingFace._resolve_model_id\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resolve the model_id from the LLM's inference_server_url\"\"\"\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_inference_endpoints\n\u001b[1;32m--> 150\u001b[0m available_endpoints \u001b[38;5;241m=\u001b[39m \u001b[43mlist_inference_endpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, HuggingFaceHub) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mrepo_id\n\u001b[0;32m    153\u001b[0m ):\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mrepo_id\n",
            "File \u001b[1;32me:\\Model-Misfit\\new-venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:7104\u001b[0m, in \u001b[0;36mHfApi.list_inference_endpoints\u001b[1;34m(self, namespace, token)\u001b[0m\n\u001b[0;32m   7102\u001b[0m \u001b[38;5;66;03m# Special case: list all endpoints for all namespaces the user has access to\u001b[39;00m\n\u001b[0;32m   7103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7104\u001b[0m     user \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhoami\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7106\u001b[0m     \u001b[38;5;66;03m# List personal endpoints first\u001b[39;00m\n\u001b[0;32m   7107\u001b[0m     endpoints: List[InferenceEndpoint] \u001b[38;5;241m=\u001b[39m list_inference_endpoints(namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_namespace(token\u001b[38;5;241m=\u001b[39mtoken))\n",
            "File \u001b[1;32me:\\Model-Misfit\\new-venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Model-Misfit\\new-venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:1322\u001b[0m, in \u001b[0;36mHfApi.whoami\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;129m@validate_hf_hub_args\u001b[39m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwhoami\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    Call HF API to know \"whoami\".\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m            not provided.\u001b[39;00m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m     r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/whoami-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 1322\u001b[0m         headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_hf_headers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# If `token` is provided and not `None`, it will be used by default.\u001b[39;49;00m\n\u001b[0;32m   1324\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Otherwise, the token must be retrieved from cache or env variable.\u001b[39;49;00m\n\u001b[0;32m   1325\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1327\u001b[0m     )\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1329\u001b[0m         hf_raise_for_status(r)\n",
            "File \u001b[1;32me:\\Model-Misfit\\new-venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py:8405\u001b[0m, in \u001b[0;36mHfApi._build_hf_headers\u001b[1;34m(self, token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m   8402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   8403\u001b[0m     \u001b[38;5;66;03m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[0;32m   8404\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[1;32m-> 8405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_hf_headers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_write_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_write_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8410\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8411\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Model-Misfit\\new-venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32me:\\Model-Misfit\\new-venv\\Lib\\site-packages\\huggingface_hub\\utils\\_headers.py:121\u001b[0m, in \u001b[0;36mbuild_hf_headers\u001b[1;34m(token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03mBuild headers dictionary to send in a HF Hub call.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m        If `token=True` but token is not saved locally.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Get auth token to send\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m token_to_send \u001b[38;5;241m=\u001b[39m \u001b[43mget_token_to_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m _validate_token_to_send(token_to_send, is_write_action\u001b[38;5;241m=\u001b[39mis_write_action)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Combine headers\u001b[39;00m\n",
            "File \u001b[1;32me:\\Model-Misfit\\new-venv\\Lib\\site-packages\\huggingface_hub\\utils\\_headers.py:153\u001b[0m, in \u001b[0;36mget_token_to_send\u001b[1;34m(token)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cached_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LocalTokenNotFoundError(\n\u001b[0;32m    154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken is required (`token=True`), but no token found. You\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m need to provide a token or be logged in to Hugging Face with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `huggingface-cli login` or `huggingface_hub.login`. See\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/settings/tokens.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m         )\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cached_token\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Case implicit use of the token is forbidden by env variable\u001b[39;00m\n",
            "\u001b[1;31mLocalTokenNotFoundError\u001b[0m: Token is required (`token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens."
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
